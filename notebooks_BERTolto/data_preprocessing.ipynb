{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "R# Preprocesamiento de los comentarios para la primera fase de fine-tuning y entrenamiento del modelo\n",
    "En esta primera fase, una vez extra칤dos los bodies de todos los issues/PRs de los repositorios listados junto con 2 comentarios de 250 del total de issues de cada repositorio, se preparar치n todos los datos para ser utilizados en el entrenamiento y ajuste fino del modelo que se utilizar치.\n",
    "\n",
    "Se seguir치n pr치cticamente los mismos pasos vistos en *c_preparing_data_for_statistics_and_ML* pero con varias diferencias claves que existen entre los modelos BERT que se utilizar치n ahora y los modelos de clasificaci칩n presentados con anterioridad (notebooks de GVTIA).\n",
    "\n",
    "Para Transformers funciona mejor un preprocesado m칤nimo y dejar la segmentaci칩n al propio tokenizador del modelo, a continuaci칩n se muestra que procedimientos similares a los anteriores se mantendr치n y cu치les se evitar치n:\n",
    "\n",
    "## Se mantendr치:\n",
    "- Normalizaci칩n de espacios/saltos de l칤nea\n",
    "- Eliminaci칩n de caracteres de control raros o poco usuales\n",
    "- Se conservar치 el uso de may칰sculas y min칰sculas, signos, n칰meros, URLs, nombres propios de vulnerabilidades o bugs (CVE-XXXX-YYYY), rutas (/etc/...), c칩digo entre backticks (`return salida`), nombres de APIs.\n",
    "- Se definir치 una longitud m치xima de tokens por comentario o el uso de *sliding window* si el texto es muy largo.\n",
    "\n",
    "## Se omitir치:\n",
    "- Pasar todo el texto a min칰sculas, los modelos RoBERTa/DistilRoBERTa que se utilizar치n utilizan may칰sculas y min칰sculas.\n",
    "- Eliminar la puntuaci칩n y stopwords.\n",
    "- Stemming / lematizaci칩n.\n",
    "- Normalizaciones agresivas de URLs/c칩digo -> se pierde se침al t칠cnica."
   ],
   "id": "50b7964ea9a2b2da"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Una vez explicado esto, se comenzar치 con el preprocesado de todos los comentarios extra칤dos de GitHub, comenzando como se ha visto ya en diversas ocasiones, con cargar el documento (.csv) en un dataframe de pandas para su uso y manipulaci칩n.\n",
    "\n",
    "En este caso, se cuenta con 2 documentos:\n",
    "- **gh_bodys_lastyear.csv**. Archivo que contiene los bodies (comentario principal) de todos los Issues/PRs en el 칰ltimo a침o de los repositorios listados para la extracci칩n de comentarios.\n",
    "- **gh_comments_lastyear.csv**. Archivo que contiene los 2 primeros comentarios de cada Issue/PR de 250 Issues/PRs por repositorio (500 comentarios por repo), en gran parte de los casos ser치n las respuestas aportadas por usuarios al body del documento anterior.\n",
    "\n",
    "En este caso, como se cuenta con 2 documentos lo que se har치 es crear 2 dataframes, uno con cada documento, para a continuaci칩n unirlos con la funci칩n `concat()` de pandas y ordenarlos seg칰n el id del Issue/PR para la clara visualizaci칩n y mantener una estructura coherente entre cuerpo principal y comentarios asociados."
   ],
   "id": "decd1abca07ad89a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T15:48:24.322990Z",
     "start_time": "2025-08-27T15:48:21.995915Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ruta de los archivos\n",
    "path_gh_bodys = \"../data/gh_comments/train-fine_tuning/gh_bodys_lastyear.csv\"\n",
    "path_gh_comments = \"../data/gh_comments/train-fine_tuning/gh_comments_lastyear.csv\"\n",
    "\n",
    "# Carga de los archivos en DataFrames\n",
    "df_bodys = pd.read_csv(path_gh_bodys)\n",
    "df_comms = pd.read_csv(path_gh_comments)"
   ],
   "id": "b0b67a9537d80fe3",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T15:48:24.584071Z",
     "start_time": "2025-08-27T15:48:24.569235Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(df_bodys.columns)\n",
    "print(df_comms.columns)"
   ],
   "id": "2ecea4e9efb540d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['repo', 'is_pr', 'issue_number', 'comment_type', 'comment_id',\n",
      "       'comment_created_at', 'comment_author', 'text', 'comment_url',\n",
      "       'context_id', 'container_title', 'container_state', 'container_url',\n",
      "       'container_created_at', 'container_updated_at', 'container_labels'],\n",
      "      dtype='object')\n",
      "Index(['kubernetes/kubernetes', 'False', '133680', 'issue_comment',\n",
      "       'github_issuecomment_IC_kwDOAToIks6_4TOW', '2025-08-25T07:51:17Z',\n",
      "       'k8s-ci-robot',\n",
      "       'This issue is currently awaiting triage.\\nIf a SIG or subproject determines this is a relevant issue, they will accept it by applying the triage/accepted label and provide further guidance.\\nThe triage/accepted label can be added by org members by writing /triage accepted in a comment.\\n\\nInstructions for interacting with me using PR comments are available here.  If you have questions or suggestions related to my behavior, please file an issue against the kubernetes-sigs/prow repository.',\n",
      "       'https://github.com/kubernetes/kubernetes/issues/133680#issuecomment-3219207062',\n",
      "       'kubernetes/kubernetes#issue:133680',\n",
      "       'Add new imagePullPolicy mode IfNewerNotPresent, that pulls image if image ID (ref/digest) on remote is not matching.',\n",
      "       'OPEN', 'https://github.com/kubernetes/kubernetes/issues/133680',\n",
      "       '2025-08-25T07:51:08Z', '2025-08-26T08:18:05Z',\n",
      "       'sig/node;kind/feature;needs-triage'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Se ha cometido un error en la escritura de la cabecera de los comentarios por escribir siempre en el mismo documento y borrar su contenido en vez de eliminar el documento antes de comenzar con una nueva extracci칩n. Vamos a tratar de repararlo sin tener que volver a realizar todo el proceso de extracci칩n.",
   "id": "928929f1de768f4e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T15:48:27.051196Z",
     "start_time": "2025-08-27T15:48:24.617155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "path_gh_bodys = Path(path_gh_bodys)\n",
    "path_gh_comments = Path(path_gh_comments)\n",
    "\n",
    "EXPECTED_COLS = [\n",
    "    'repo','is_pr','issue_number','comment_type','comment_id','comment_created_at','comment_author',\n",
    "    'text','comment_url','context_id','container_title','container_state','container_url',\n",
    "    'container_created_at','container_updated_at','container_labels'\n",
    "]\n",
    "\n",
    "def read_with_header_fix(p: Path) -> pd.DataFrame:\n",
    "    # Se lee 1 fila para inspeccionar columnas\n",
    "    probe = pd.read_csv(p, nrows=1)\n",
    "    if list(probe.columns) == EXPECTED_COLS:\n",
    "        return pd.read_csv(p)\n",
    "    # Si no coincide, reinterpretamos: no hay cabecera -> header=None + names=EXPECTED_COLS\n",
    "    return pd.read_csv(p, header=None, names=EXPECTED_COLS)\n",
    "\n",
    "df_bodys = read_with_header_fix(path_gh_bodys)\n",
    "df_comms = read_with_header_fix(path_gh_comments)\n",
    "\n",
    "# Se unen ambos DataFrames\n",
    "df_gh = pd.concat([df_bodys, df_comms], ignore_index=True)\n",
    "\n",
    "# Tipos y ordenaci칩n\n",
    "df_gh['comment_created_at'] = pd.to_datetime(df_gh['comment_created_at'], errors='coerce', utc=True)\n",
    "df_gh.loc[df_gh['comment_created_at'].isna(), 'comment_created_at'] = pd.to_datetime(df_gh['container_created_at'], errors='coerce', utc=True)\n",
    "\n",
    "order_map = {'issue_body':0, 'pr_body':0} # Bodies primero -> coherencia\n",
    "df_gh['order'] = df_gh['comment_type'].map(order_map).fillna(1).astype(int)\n",
    "\n",
    "df_gh = df_gh.sort_values(by=['repo','issue_number','order','comment_created_at','comment_id'], kind='mergesort').drop(columns=['order'])\n",
    "\n",
    "# Normalizar booleano -> OPCIONAL\n",
    "df_gh['is_pr'] = df_gh['is_pr'].astype(str).str.lower().map({'true':True, 'false':False})"
   ],
   "id": "3034471a4637f6e8",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T15:48:27.094100Z",
     "start_time": "2025-08-27T15:48:27.082226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Muestra para comprobar que se ha ejecutado correctamente\n",
    "print(df_bodys.columns)\n",
    "print(df_comms.columns)\n",
    "\n",
    "df_gh.head(10).T\n",
    "print(len(df_gh))"
   ],
   "id": "f7895ae432b8ec3b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['repo', 'is_pr', 'issue_number', 'comment_type', 'comment_id',\n",
      "       'comment_created_at', 'comment_author', 'text', 'comment_url',\n",
      "       'context_id', 'container_title', 'container_state', 'container_url',\n",
      "       'container_created_at', 'container_updated_at', 'container_labels'],\n",
      "      dtype='object')\n",
      "Index(['repo', 'is_pr', 'issue_number', 'comment_type', 'comment_id',\n",
      "       'comment_created_at', 'comment_author', 'text', 'comment_url',\n",
      "       'context_id', 'container_title', 'container_state', 'container_url',\n",
      "       'container_created_at', 'container_updated_at', 'container_labels'],\n",
      "      dtype='object')\n",
      "108078\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ahora s칤 est치n todos los comentarios bien ordenados. Antes de comenzar con el preprocesado vamos a guardar el dataframe en una base de datos.",
   "id": "65043b29d28ed666"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T15:48:27.141219Z",
     "start_time": "2025-08-27T15:48:27.127247Z"
    }
   },
   "cell_type": "code",
   "source": "print(len(df_gh))",
   "id": "b425f5858db09200",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108078\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T15:48:34.345574Z",
     "start_time": "2025-08-27T15:48:27.172604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sqlite3\n",
    "\n",
    "db_gh = \"../data/gh_comments/train-fine_tuning/gh_dataset_lastyear.db\"\n",
    "con = sqlite3.connect(db_gh)\n",
    "df_gh.to_sql('gh_dataset', con, if_exists='replace', index=False)\n",
    "con.close()"
   ],
   "id": "de15d1140cc5ed4",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T16:09:37.687244Z",
     "start_time": "2025-08-27T16:09:37.516677Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pathlib\n",
    "\n",
    "db_gh = pathlib.Path(\"../data/gh_comments/train-fine_tuning/gh_dataset_lastyear.db\")\n",
    "with sqlite3.connect(db_gh) as con:\n",
    "    n_rows = con.execute(\"SELECT COUNT(*) FROM gh_dataset\").fetchone()[0]\n",
    "print(f\"Filas en la tabla: {n_rows:,}\")\n",
    "\n",
    "with sqlite3.connect(db_gh) as con:\n",
    "    sample = con.execute(\"\"\"\n",
    "        SELECT * FROM gh_dataset\n",
    "        ORDER BY RANDOM()\n",
    "        LIMIT 10\n",
    "    \"\"\").fetchall()\n",
    "sample[:3]   # imprime tres filas de ejemplo\n"
   ],
   "id": "bbbf70e27843042a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas en la tabla: 108,078\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('grafana/grafana',\n",
       "  0,\n",
       "  105099,\n",
       "  'issue_body',\n",
       "  'github_issuebody_grafana/grafana#105099',\n",
       "  '2025-05-08 10:28:52+00:00',\n",
       "  'joshhunt',\n",
       "  'Description\\nVerify that the Betterer CI check GitHub Action is functioning correctly in the following release branches:\\n\\nrelease-11.4.5\\nrelease-11.5.5\\nrelease-11.3.7\\n\\nIt should work in all active release branches.\\nSee https://github.com/grafana/grafana/actions/runs/14903136485/job/41859445141?pr=104905 for an example.\\nI believe this is because we copied the actions from main into all release branches, but the betterer check in main relies on a yarn command which is not present in earlier release branches. We would want to either backport the yarn command, or update the action in the branches.\\nSteps to Validate\\n\\nTrigger the Betterer CI check Github Action for each specified branch.\\nEnsure the CI check completes successfully without errors.\\n\\nExpected Outcome\\nThe Betterer CI check should pass for all release branches',\n",
       "  'https://github.com/grafana/grafana/issues/105099',\n",
       "  'grafana/grafana#issue:105099',\n",
       "  'Ensure Betterer CI check GitHub Action works on release branches',\n",
       "  'CLOSED',\n",
       "  'https://github.com/grafana/grafana/issues/105099',\n",
       "  '2025-05-08T10:28:52Z',\n",
       "  '2025-06-20T10:34:12Z',\n",
       "  'internal'),\n",
       " ('kubernetes/kubernetes',\n",
       "  1,\n",
       "  130498,\n",
       "  'pr_body',\n",
       "  'github_prbody_kubernetes/kubernetes#130498',\n",
       "  '2025-02-28 18:46:35+00:00',\n",
       "  'swatisehgal',\n",
       "  'What type of PR is this?\\n/kind cleanup\\n\\nWhat this PR does / why we need it:\\nThis PR adds e2e tests for distribute-cpus-across-numa CPU Manager policy option.\\nWhich issue(s) this PR fixes:\\nThis work is being done as part of  Beta graduation of the policy option.\\nEnhancement Issue: kubernetes/enhancements#2902\\nSpecial notes for your reviewer:\\nDoes this PR introduce a user-facing change?\\n\\nNONE',\n",
       "  'https://github.com/kubernetes/kubernetes/pull/130498',\n",
       "  'kubernetes/kubernetes#pr:130498',\n",
       "  'node: cpumgr: e2e: Tests for `distribute-cpus-across-numa` policy option',\n",
       "  'MERGED',\n",
       "  'https://github.com/kubernetes/kubernetes/pull/130498',\n",
       "  '2025-02-28T18:46:35Z',\n",
       "  '2025-03-19T17:19:08Z',\n",
       "  'area/test;priority/important-soon;kind/cleanup;lgtm;sig/node;size/L;release-note-none;approved;cncf-cla: yes;sig/testing;triage/accepted'),\n",
       " ('openssl/openssl',\n",
       "  1,\n",
       "  28208,\n",
       "  'pr_body',\n",
       "  'github_prbody_openssl/openssl#28208',\n",
       "  '2025-08-08 13:21:27+00:00',\n",
       "  'jogme',\n",
       "  'Fixes: openssl/project#1316\\nChecklist\\n\\n\\n documentation is added or updated\\n tests are added or updated',\n",
       "  'https://github.com/openssl/openssl/pull/28208',\n",
       "  'openssl/openssl#pr:28208',\n",
       "  'Fix coverity issue #1662037',\n",
       "  'CLOSED',\n",
       "  'https://github.com/openssl/openssl/pull/28208',\n",
       "  '2025-08-08T13:21:27Z',\n",
       "  '2025-08-10T21:49:31Z',\n",
       "  'branch: master;approval: ready to merge;triaged: bug;tests: exempted')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Ahora s칤 se proceder치 al procesamiento del dataset para dejarlo preparado para el modelo BERT que se utilizar치, RoBERTa o DistilRoBERTa. Este proceso se va a definir en una serie de scripts .py, cada uno con el objetivo de realizar una tarea para su reutilizaci칩n en otros puntos del proyecto (cuando se haga el de reddit, u otros comentarios de github) de forma que estos sean agn칩sticos al sistema del que se extraen los comentarios que ser치n utilizados por el modelo.\n",
    "\n",
    "Del mismo modo, tras el procesamiento de los datos, el resultado del procesado ser치 almacenado en archivos `.parquet` por su ligereza y agilidad a la hora de ser manipulados y consumidos por modelos BERT. Las principales ventajas de este formato son:\n",
    "- M치s peque침o: compresi칩n por columna, pesa de 2 a 5 veces menos que un `.csv`\n",
    "- M치s r치pido: lee solo las columnas que se necesitan (\"column pruning\") y aplica vectorizaci칩n.\n",
    "- Conserva tipos: fechas, booleanos, enteros \"nullable\", etc. (`.csv`los pierde)\n",
    "- Esquema: guarda el _schema_ dentro del archivo -> menos sorpresas al cargarlo\n",
    "\n",
    "Por estas caracter칤sticas el formato es el preferido para pipelines de datos/ML. En este caso la estructura que se utilizar치 ser치:\n",
    "- `merged.parquet` = ser치 el dataset completo tras ingesta y normalizaci칩n ligera.\n",
    "- `split_train.parquet`, `split_dev.parquet`, `split_test.parquet` = particiones del dataset ya divididas, listas para su tokenizaci칩n.\n",
    "\n",
    "#### Ventajas frente a CSV\n",
    "- Evita problemas de comas y saltos de l칤nea\n",
    "- Mantiene las fechas (`created_at`), booleanos (`is_pr`) y enteros sin perder el tipo.\n",
    "- Carga solo las columnas necesarias -> menor uso de RAM y tiempo de ejecuci칩n."
   ],
   "id": "17b3a603ab9a704c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Ejecuci칩n del preprocesado de datos\n",
    "Se han definido varios scripts, cada uno con una funci칩n en el preprocesado de datos para modelos BERT, a  los cu치les se les llamar치 desde este notebook con los argumentos correspondientes para realizar este proceso.\n",
    "\n",
    "Las funciones reutilizables para el pipeline est치n definidas en `prep_utils.py`. Normaliza texto \"ligero\", mapea columnas heterog칠neas (GH/Reddit) al esquema core (id, text, label, source, created_at, context_id), lee CSV/SQLite y guarda Parquet.\n",
    "El objetivo principal de estas funciones es su utilizaci칩n cuando se desea agnosticismo de fuente (Github/Reddit) y un preprocesado m칤nimo ideal para Transformers."
   ],
   "id": "3b3d14442f2d3c47"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### `ingest_merge.py`\n",
    "Combina una o varias entradas en un 칰nico DataFrame, deduplica el contenido por `id`, aplica normalizaci칩n ligera y guarda `merged.parquet` + meta. Se le da como input el archivo `.db` o los `.csv` deseados, produciendo en la salida un DF en formato `.parquet`."
   ],
   "id": "25430a09c3406432"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T15:48:34.392238Z",
     "start_time": "2025-08-27T15:48:34.374366Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ],
   "id": "159d1393077e3707",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\Mis documentos\\CLASE\\0. TFG\\BERTolto\\notebooks_BERTolto\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T15:48:34.439814Z",
     "start_time": "2025-08-27T15:48:34.422396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define la ruta de tu base de datos tal como la usas\n",
    "db_gh = \"../data/gh_comments/train-fine_tuning/gh_dataset_lastyear.db\"\n",
    "\n",
    "try:\n",
    "    con = sqlite3.connect(db_gh)\n",
    "    # Intenta leer algunas filas de la tabla 'gh_dataset'\n",
    "    test_df = pd.read_sql(\"SELECT * FROM gh_dataset LIMIT 5\", con)\n",
    "    con.close()\n",
    "\n",
    "    print(f\"\\nVerificaci칩n de la base de datos '{db_gh}':\")\n",
    "    print(f\"N칰mero de filas recuperadas de 'gh_dataset': {len(test_df)}\")\n",
    "    if not test_df.empty:\n",
    "        print(\"Primeras filas de 'gh_dataset' (limitadas a 5):\")\n",
    "        print(test_df.head())\n",
    "    else:\n",
    "        print(\"춰Advertencia! La tabla 'gh_dataset' est치 vac칤a o no se pudieron recuperar datos.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ocurri칩 un error al intentar verificar la base de datos: {e}\")\n",
    "    if 'gh_dataset_lastyear.db' not in str(e) and 'no such table' in str(e):\n",
    "        print(\"Aseg칰rate de que la base de datos y la tabla ('gh_dataset') existen y el nombre es correcto.\")"
   ],
   "id": "2e6a26f024264fe1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verificaci칩n de la base de datos '../data/gh_comments/train-fine_tuning/gh_dataset_lastyear.db':\n",
      "N칰mero de filas recuperadas de 'gh_dataset': 5\n",
      "Primeras filas de 'gh_dataset' (limitadas a 5):\n",
      "                                 repo  is_pr  issue_number   comment_type  \\\n",
      "0  electron-userland/electron-builder      0           690  issue_comment   \n",
      "1  electron-userland/electron-builder      0          2674  issue_comment   \n",
      "2  electron-userland/electron-builder      0          3009  issue_comment   \n",
      "3  electron-userland/electron-builder      0          3009  issue_comment   \n",
      "4  electron-userland/electron-builder      0          3124  issue_comment   \n",
      "\n",
      "                                comment_id         comment_created_at  \\\n",
      "0  github_issuecomment_IC_kwDOAiVL48626ksv  2025-07-14 10:14:03+00:00   \n",
      "1  github_issuecomment_IC_kwDOAiVL4866KmSG  2025-07-26 20:27:33+00:00   \n",
      "2  github_issuecomment_IC_kwDOAiVL486w_HsW  2025-06-13 07:10:06+00:00   \n",
      "3  github_issuecomment_IC_kwDOAiVL486x74HL  2025-06-18 18:12:08+00:00   \n",
      "4  github_issuecomment_IC_kwDOAiVL486yE1aY  2025-06-19 10:41:44+00:00   \n",
      "\n",
      "  comment_author                                               text  \\\n",
      "0      Wiktor102  Can confirm that specifying the appUrl option ...   \n",
      "1   siikakamania  Ok found problem by elimination. I have folder...   \n",
      "2         theIYD  Anyone who was able to crack auto-update with ...   \n",
      "3        prayash                                           nice mna   \n",
      "4     minhtan143                        This is a necessary feature   \n",
      "\n",
      "                                         comment_url  \\\n",
      "0  https://github.com/electron-userland/electron-...   \n",
      "1  https://github.com/electron-userland/electron-...   \n",
      "2  https://github.com/electron-userland/electron-...   \n",
      "3  https://github.com/electron-userland/electron-...   \n",
      "4  https://github.com/electron-userland/electron-...   \n",
      "\n",
      "                                      context_id  \\\n",
      "0   electron-userland/electron-builder#issue:690   \n",
      "1  electron-userland/electron-builder#issue:2674   \n",
      "2  electron-userland/electron-builder#issue:3009   \n",
      "3  electron-userland/electron-builder#issue:3009   \n",
      "4  electron-userland/electron-builder#issue:3124   \n",
      "\n",
      "                                     container_title container_state  \\\n",
      "0  Error: Filename can either be an absolute HTTP...          CLOSED   \n",
      "1                    makensis.exe exited with code 1          CLOSED   \n",
      "2               How to use electron-forge-maker-nsis          CLOSED   \n",
      "3               How to use electron-forge-maker-nsis          CLOSED   \n",
      "4       How to add a custom page/field to NSIS setup          CLOSED   \n",
      "\n",
      "                                       container_url  container_created_at  \\\n",
      "0  https://github.com/electron-userland/electron-...  2016-08-22T17:50:08Z   \n",
      "1  https://github.com/electron-userland/electron-...  2018-03-08T12:31:10Z   \n",
      "2  https://github.com/electron-userland/electron-...  2018-06-12T16:48:57Z   \n",
      "3  https://github.com/electron-userland/electron-...  2018-06-12T16:48:57Z   \n",
      "4  https://github.com/electron-userland/electron-...  2018-07-17T20:19:17Z   \n",
      "\n",
      "   container_updated_at                                  container_labels  \n",
      "0  2025-07-14T10:14:03Z  help wanted;investigate;backlog;Squirrel.Windows  \n",
      "1  2025-07-26T20:27:33Z                                              None  \n",
      "2  2025-06-18T18:12:08Z                                           backlog  \n",
      "3  2025-06-18T18:12:08Z                                           backlog  \n",
      "4  2025-06-19T10:41:44Z                                           backlog  \n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T16:10:51.482316Z",
     "start_time": "2025-08-27T16:10:51.457431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.data_prep.prep_utils import load_sqlite\n",
    "load_sqlite(\"../data/gh_comments/train-fine_tuning/gh_dataset_lastyear.db\",\n",
    "            table=\"gh_dataset\",\n",
    "            limit=10)"
   ],
   "id": "96b8f079d2a99c8f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                 repo  is_pr  issue_number   comment_type  \\\n",
       "0  electron-userland/electron-builder      0           690  issue_comment   \n",
       "1  electron-userland/electron-builder      0          2674  issue_comment   \n",
       "2  electron-userland/electron-builder      0          3009  issue_comment   \n",
       "3  electron-userland/electron-builder      0          3009  issue_comment   \n",
       "4  electron-userland/electron-builder      0          3124  issue_comment   \n",
       "5  electron-userland/electron-builder      0          3185  issue_comment   \n",
       "6  electron-userland/electron-builder      0          3322  issue_comment   \n",
       "7  electron-userland/electron-builder      0          3376  issue_comment   \n",
       "8  electron-userland/electron-builder      0          3376  issue_comment   \n",
       "9  electron-userland/electron-builder      0          3632  issue_comment   \n",
       "\n",
       "                                comment_id         comment_created_at  \\\n",
       "0  github_issuecomment_IC_kwDOAiVL48626ksv  2025-07-14 10:14:03+00:00   \n",
       "1  github_issuecomment_IC_kwDOAiVL4866KmSG  2025-07-26 20:27:33+00:00   \n",
       "2  github_issuecomment_IC_kwDOAiVL486w_HsW  2025-06-13 07:10:06+00:00   \n",
       "3  github_issuecomment_IC_kwDOAiVL486x74HL  2025-06-18 18:12:08+00:00   \n",
       "4  github_issuecomment_IC_kwDOAiVL486yE1aY  2025-06-19 10:41:44+00:00   \n",
       "5  github_issuecomment_IC_kwDOAiVL4868Kgl1  2025-08-05 22:59:10+00:00   \n",
       "6  github_issuecomment_IC_kwDOAiVL486577nr  2025-07-25 17:00:17+00:00   \n",
       "7  github_issuecomment_IC_kwDOAiVL486d8ofG  2025-02-11 06:33:25+00:00   \n",
       "8  github_issuecomment_IC_kwDOAiVL486yLFqm  2025-06-19 22:14:59+00:00   \n",
       "9  github_issuecomment_IC_kwDOAiVL487ADWUN  2025-08-26 00:08:25+00:00   \n",
       "\n",
       "   comment_author                                               text  \\\n",
       "0       Wiktor102  Can confirm that specifying the appUrl option ...   \n",
       "1    siikakamania  Ok found problem by elimination. I have folder...   \n",
       "2          theIYD  Anyone who was able to crack auto-update with ...   \n",
       "3         prayash                                           nice mna   \n",
       "4      minhtan143                        This is a necessary feature   \n",
       "5    oceangravity                                                  游땴   \n",
       "6         Pritraj  It is 2024, what happend on this issue? I hope...   \n",
       "7     hanzhenfang                                        same to me,   \n",
       "8        devPablo  I'm facing the same issue, need dynamic \"url\" ...   \n",
       "9  github-actions  This issue is stale because it has been open f...   \n",
       "\n",
       "                                         comment_url  \\\n",
       "0  https://github.com/electron-userland/electron-...   \n",
       "1  https://github.com/electron-userland/electron-...   \n",
       "2  https://github.com/electron-userland/electron-...   \n",
       "3  https://github.com/electron-userland/electron-...   \n",
       "4  https://github.com/electron-userland/electron-...   \n",
       "5  https://github.com/electron-userland/electron-...   \n",
       "6  https://github.com/electron-userland/electron-...   \n",
       "7  https://github.com/electron-userland/electron-...   \n",
       "8  https://github.com/electron-userland/electron-...   \n",
       "9  https://github.com/electron-userland/electron-...   \n",
       "\n",
       "                                      context_id  \\\n",
       "0   electron-userland/electron-builder#issue:690   \n",
       "1  electron-userland/electron-builder#issue:2674   \n",
       "2  electron-userland/electron-builder#issue:3009   \n",
       "3  electron-userland/electron-builder#issue:3009   \n",
       "4  electron-userland/electron-builder#issue:3124   \n",
       "5  electron-userland/electron-builder#issue:3185   \n",
       "6  electron-userland/electron-builder#issue:3322   \n",
       "7  electron-userland/electron-builder#issue:3376   \n",
       "8  electron-userland/electron-builder#issue:3376   \n",
       "9  electron-userland/electron-builder#issue:3632   \n",
       "\n",
       "                                     container_title container_state  \\\n",
       "0  Error: Filename can either be an absolute HTTP...          CLOSED   \n",
       "1                    makensis.exe exited with code 1          CLOSED   \n",
       "2               How to use electron-forge-maker-nsis          CLOSED   \n",
       "3               How to use electron-forge-maker-nsis          CLOSED   \n",
       "4       How to add a custom page/field to NSIS setup          CLOSED   \n",
       "5      Nested node_modules disappears after building          CLOSED   \n",
       "6               Q : Does MSI work with auto-update ?          CLOSED   \n",
       "7                         Custom path for latest.yml          CLOSED   \n",
       "8                         Custom path for latest.yml          CLOSED   \n",
       "9  (Windows) Not installing after updating and qu...            OPEN   \n",
       "\n",
       "                                       container_url  container_created_at  \\\n",
       "0  https://github.com/electron-userland/electron-...  2016-08-22T17:50:08Z   \n",
       "1  https://github.com/electron-userland/electron-...  2018-03-08T12:31:10Z   \n",
       "2  https://github.com/electron-userland/electron-...  2018-06-12T16:48:57Z   \n",
       "3  https://github.com/electron-userland/electron-...  2018-06-12T16:48:57Z   \n",
       "4  https://github.com/electron-userland/electron-...  2018-07-17T20:19:17Z   \n",
       "5  https://github.com/electron-userland/electron-...  2018-07-28T18:22:53Z   \n",
       "6  https://github.com/electron-userland/electron-...  2018-09-14T20:08:28Z   \n",
       "7  https://github.com/electron-userland/electron-...  2018-10-10T10:35:13Z   \n",
       "8  https://github.com/electron-userland/electron-...  2018-10-10T10:35:13Z   \n",
       "9  https://github.com/electron-userland/electron-...  2019-01-24T12:36:05Z   \n",
       "\n",
       "   container_updated_at                                  container_labels  \n",
       "0  2025-07-14T10:14:03Z  help wanted;investigate;backlog;Squirrel.Windows  \n",
       "1  2025-07-26T20:27:33Z                                              None  \n",
       "2  2025-06-18T18:12:08Z                                           backlog  \n",
       "3  2025-06-18T18:12:08Z                                           backlog  \n",
       "4  2025-06-19T10:41:44Z                                           backlog  \n",
       "5  2025-08-05T22:59:10Z                                              None  \n",
       "6  2025-07-25T17:00:17Z                                      question;msi  \n",
       "7  2025-06-19T22:14:59Z                                          question  \n",
       "8  2025-06-19T22:14:59Z                                          question  \n",
       "9  2025-08-26T00:08:26Z            bug;investigate;electron-updater;Stale  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>is_pr</th>\n",
       "      <th>issue_number</th>\n",
       "      <th>comment_type</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment_created_at</th>\n",
       "      <th>comment_author</th>\n",
       "      <th>text</th>\n",
       "      <th>comment_url</th>\n",
       "      <th>context_id</th>\n",
       "      <th>container_title</th>\n",
       "      <th>container_state</th>\n",
       "      <th>container_url</th>\n",
       "      <th>container_created_at</th>\n",
       "      <th>container_updated_at</th>\n",
       "      <th>container_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>electron-userland/electron-builder</td>\n",
       "      <td>0</td>\n",
       "      <td>690</td>\n",
       "      <td>issue_comment</td>\n",
       "      <td>github_issuecomment_IC_kwDOAiVL48626ksv</td>\n",
       "      <td>2025-07-14 10:14:03+00:00</td>\n",
       "      <td>Wiktor102</td>\n",
       "      <td>Can confirm that specifying the appUrl option ...</td>\n",
       "      <td>https://github.com/electron-userland/electron-...</td>\n",
       "      <td>electron-userland/electron-builder#issue:690</td>\n",
       "      <td>Error: Filename can either be an absolute HTTP...</td>\n",
       "      <td>CLOSED</td>\n",
       "      <td>https://github.com/electron-userland/electron-...</td>\n",
       "      <td>2016-08-22T17:50:08Z</td>\n",
       "      <td>2025-07-14T10:14:03Z</td>\n",
       "      <td>help wanted;investigate;backlog;Squirrel.Windows</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>electron-userland/electron-builder</td>\n",
       "      <td>0</td>\n",
       "      <td>2674</td>\n",
       "      <td>issue_comment</td>\n",
       "      <td>github_issuecomment_IC_kwDOAiVL4866KmSG</td>\n",
       "      <td>2025-07-26 20:27:33+00:00</td>\n",
       "      <td>siikakamania</td>\n",
       "      <td>Ok found problem by elimination. I have folder...</td>\n",
       "      <td>https://github.com/electron-userland/electron-...</td>\n",
       "      <td>electron-userland/electron-builder#issue:2674</td>\n",
       "      <td>makensis.exe exited with code 1</td>\n",
       "      <td>CLOSED</td>\n",
       "      <td>https://github.com/electron-userland/electron-...</td>\n",
       "      <td>2018-03-08T12:31:10Z</td>\n",
       "      <td>2025-07-26T20:27:33Z</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>electron-userland/electron-builder</td>\n",
       "      <td>0</td>\n",
       "      <td>3009</td>\n",
       "      <td>issue_comment</td>\n",
       "      <td>github_issuecomment_IC_kwDOAiVL486w_HsW</td>\n",
       "      <td>2025-06-13 07:10:06+00:00</td>\n",
       "      <td>theIYD</td>\n",
       "      <td>Anyone who was able to crack auto-update with ...</td>\n",
       "      <td>https://github.com/electron-userland/electron-...</td>\n",
       "      <td>electron-userland/electron-builder#issue:3009</td>\n",
       "      <td>How to use electron-forge-maker-nsis</td>\n",
       "      <td>CLOSED</td>\n",
       "      <td>https://github.com/electron-userland/electron-...</td>\n",
       "      <td>2018-06-12T16:48:57Z</td>\n",
       "      <td>2025-06-18T18:12:08Z</td>\n",
       "      <td>backlog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>electron-userland/electron-builder</td>\n",
       "      <td>0</td>\n",
       "      <td>3009</td>\n",
       "      <td>issue_comment</td>\n",
       "      <td>github_issuecomment_IC_kwDOAiVL486x74HL</td>\n",
       "      <td>2025-06-18 18:12:08+00:00</td>\n",
       "      <td>prayash</td>\n",
       "      <td>nice mna</td>\n",
       "      <td>https://github.com/electron-userland/electron-...</td>\n",
       "      <td>electron-userland/electron-builder#issue:3009</td>\n",
       "      <td>How to use electron-forge-maker-nsis</td>\n",
       "      <td>CLOSED</td>\n",
       "      <td>https://github.com/electron-userland/electron-...</td>\n",
       "      <td>2018-06-12T16:48:57Z</td>\n",
       "      <td>2025-06-18T18:12:08Z</td>\n",
       "      <td>backlog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>electron-userland/electron-builder</td>\n",
       "      <td>0</td>\n",
       "      <td>3124</td>\n",
       "      <td>issue_comment</td>\n",
       "      <td>github_issuecomment_IC_kwDOAiVL486yE1aY</td>\n",
       "      <td>2025-06-19 10:41:44+00:00</td>\n",
       "      <td>minhtan143</td>\n",
       "      <td>This is a necessary feature</td>\n",
       "      <td>https://github.com/electron-userland/electron-...</td>\n",
       "      <td>electron-userland/electron-builder#issue:3124</td>\n",
       "      <td>How to add a custom page/field to NSIS setup</td>\n",
       "      <td>CLOSED</td>\n",
       "      <td>https://github.com/electron-userland/electron-...</td>\n",
       "      <td>2018-07-17T20:19:17Z</td>\n",
       "      <td>2025-06-19T10:41:44Z</td>\n",
       "      <td>backlog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>electron-userland/electron-builder</td>\n",
       "      <td>0</td>\n",
       "      <td>3185</td>\n",
       "      <td>issue_comment</td>\n",
       "      <td>github_issuecomment_IC_kwDOAiVL4868Kgl1</td>\n",
       "      <td>2025-08-05 22:59:10+00:00</td>\n",
       "      <td>oceangravity</td>\n",
       "      <td>游땴</td>\n",
       "      <td>https://github.com/electron-userland/electron-...</td>\n",
       "      <td>electron-userland/electron-builder#issue:3185</td>\n",
       "      <td>Nested node_modules disappears after building</td>\n",
       "      <td>CLOSED</td>\n",
       "      <td>https://github.com/electron-userland/electron-...</td>\n",
       "      <td>2018-07-28T18:22:53Z</td>\n",
       "      <td>2025-08-05T22:59:10Z</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>electron-userland/electron-builder</td>\n",
       "      <td>0</td>\n",
       "      <td>3322</td>\n",
       "      <td>issue_comment</td>\n",
       "      <td>github_issuecomment_IC_kwDOAiVL486577nr</td>\n",
       "      <td>2025-07-25 17:00:17+00:00</td>\n",
       "      <td>Pritraj</td>\n",
       "      <td>It is 2024, what happend on this issue? I hope...</td>\n",
       "      <td>https://github.com/electron-userland/electron-...</td>\n",
       "      <td>electron-userland/electron-builder#issue:3322</td>\n",
       "      <td>Q : Does MSI work with auto-update ?</td>\n",
       "      <td>CLOSED</td>\n",
       "      <td>https://github.com/electron-userland/electron-...</td>\n",
       "      <td>2018-09-14T20:08:28Z</td>\n",
       "      <td>2025-07-25T17:00:17Z</td>\n",
       "      <td>question;msi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>electron-userland/electron-builder</td>\n",
       "      <td>0</td>\n",
       "      <td>3376</td>\n",
       "      <td>issue_comment</td>\n",
       "      <td>github_issuecomment_IC_kwDOAiVL486d8ofG</td>\n",
       "      <td>2025-02-11 06:33:25+00:00</td>\n",
       "      <td>hanzhenfang</td>\n",
       "      <td>same to me,</td>\n",
       "      <td>https://github.com/electron-userland/electron-...</td>\n",
       "      <td>electron-userland/electron-builder#issue:3376</td>\n",
       "      <td>Custom path for latest.yml</td>\n",
       "      <td>CLOSED</td>\n",
       "      <td>https://github.com/electron-userland/electron-...</td>\n",
       "      <td>2018-10-10T10:35:13Z</td>\n",
       "      <td>2025-06-19T22:14:59Z</td>\n",
       "      <td>question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>electron-userland/electron-builder</td>\n",
       "      <td>0</td>\n",
       "      <td>3376</td>\n",
       "      <td>issue_comment</td>\n",
       "      <td>github_issuecomment_IC_kwDOAiVL486yLFqm</td>\n",
       "      <td>2025-06-19 22:14:59+00:00</td>\n",
       "      <td>devPablo</td>\n",
       "      <td>I'm facing the same issue, need dynamic \"url\" ...</td>\n",
       "      <td>https://github.com/electron-userland/electron-...</td>\n",
       "      <td>electron-userland/electron-builder#issue:3376</td>\n",
       "      <td>Custom path for latest.yml</td>\n",
       "      <td>CLOSED</td>\n",
       "      <td>https://github.com/electron-userland/electron-...</td>\n",
       "      <td>2018-10-10T10:35:13Z</td>\n",
       "      <td>2025-06-19T22:14:59Z</td>\n",
       "      <td>question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>electron-userland/electron-builder</td>\n",
       "      <td>0</td>\n",
       "      <td>3632</td>\n",
       "      <td>issue_comment</td>\n",
       "      <td>github_issuecomment_IC_kwDOAiVL487ADWUN</td>\n",
       "      <td>2025-08-26 00:08:25+00:00</td>\n",
       "      <td>github-actions</td>\n",
       "      <td>This issue is stale because it has been open f...</td>\n",
       "      <td>https://github.com/electron-userland/electron-...</td>\n",
       "      <td>electron-userland/electron-builder#issue:3632</td>\n",
       "      <td>(Windows) Not installing after updating and qu...</td>\n",
       "      <td>OPEN</td>\n",
       "      <td>https://github.com/electron-userland/electron-...</td>\n",
       "      <td>2019-01-24T12:36:05Z</td>\n",
       "      <td>2025-08-26T00:08:26Z</td>\n",
       "      <td>bug;investigate;electron-updater;Stale</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T16:11:35.715074Z",
     "start_time": "2025-08-27T16:11:26.284892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import subprocess, sys\n",
    "\n",
    "base = \"../src/data_prep\"\n",
    "\n",
    "# 1. Ingesta + merge (de CSVs o db en SQLite)\n",
    "# Como ya tengo el dataset directamente almacenado en un .db\n",
    "subprocess.run([sys.executable, f\"{base}/ingest_merge.py\",\n",
    "                \"--sqlite-db\", \"../data/gh_comments/train-fine_tuning/gh_dataset_lastyear.db\",\n",
    "                \"--table\", \"gh_dataset\",\n",
    "                \"--out-parquet\", \"../src/artifacts/prep/merged.parquet\",\n",
    "                \"--out-meta\", \"../src/artifacts/prep/merged_meta.json\"\n",
    "                ], check=True)\n"
   ],
   "id": "2087c680aa62567a",
   "outputs": [
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['C:\\\\Users\\\\diego\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\python.exe', '../src/data_prep/ingest_merge.py', '--sqlite-db', '../data/gh_comments/train-fine_tuning/gh_dataset_lastyear.db', '--table', 'gh_dataset', '--out-parquet', '../src/artifacts/prep/merged.parquet', '--out-meta', '../src/artifacts/prep/merged_meta.json']' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mCalledProcessError\u001B[0m                        Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[23], line 7\u001B[0m\n\u001B[0;32m      3\u001B[0m base \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../src/data_prep\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# 1. Ingesta + merge (de CSVs o db en SQLite)\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# Como ya tengo el dataset directamente almacenado en un .db\u001B[39;00m\n\u001B[1;32m----> 7\u001B[0m \u001B[43msubprocess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43msys\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecutable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m../src/data_prep/ingest_merge.py\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m--sqlite-db\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m../data/gh_comments/train-fine_tuning/gh_dataset_lastyear.db\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m--table\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgh_dataset\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m--out-parquet\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m../src/artifacts/prep/merged.parquet\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m--out-meta\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m../src/artifacts/prep/merged_meta.json\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\n\u001B[0;32m     12\u001B[0m \u001B[43m                \u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcheck\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\subprocess.py:526\u001B[0m, in \u001B[0;36mrun\u001B[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001B[0m\n\u001B[0;32m    524\u001B[0m     retcode \u001B[38;5;241m=\u001B[39m process\u001B[38;5;241m.\u001B[39mpoll()\n\u001B[0;32m    525\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m check \u001B[38;5;129;01mand\u001B[39;00m retcode:\n\u001B[1;32m--> 526\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m CalledProcessError(retcode, process\u001B[38;5;241m.\u001B[39margs,\n\u001B[0;32m    527\u001B[0m                                  output\u001B[38;5;241m=\u001B[39mstdout, stderr\u001B[38;5;241m=\u001B[39mstderr)\n\u001B[0;32m    528\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m CompletedProcess(process\u001B[38;5;241m.\u001B[39margs, retcode, stdout, stderr)\n",
      "\u001B[1;31mCalledProcessError\u001B[0m: Command '['C:\\\\Users\\\\diego\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\python.exe', '../src/data_prep/ingest_merge.py', '--sqlite-db', '../data/gh_comments/train-fine_tuning/gh_dataset_lastyear.db', '--table', 'gh_dataset', '--out-parquet', '../src/artifacts/prep/merged.parquet', '--out-meta', '../src/artifacts/prep/merged_meta.json']' returned non-zero exit status 1."
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### `quick_report.py`\n",
    "Muestra por pantalla un resumen del Parquet aportado en el input: n췈 de filas, distribuci칩n de `label`, distribuci칩n de `source`, rango de `created_at`.\n",
    "Es 칰til para la verificaci칩n visual de que la ingesta es correcta antes del split/tokenizaci칩n e ideal para detectar desbalanceos fuertes o rangos temporales inesperados antes de la fase de entrenamiento."
   ],
   "id": "4f941dffedc431b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Informe r치pido\n",
    "subprocess.run([sys.executable, f\"{base}/quick_report.py\",\n",
    "                \"--in-parquet\", \"src/artifacts/prep/merged.parquet\"\n",
    "                ], check=True)"
   ],
   "id": "c054999514390b34"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### `split_thread_temporal.py`\n",
    "Divide el DF `merged.parquet` en train/dev/test respetando hilos (`context_id`) y orden temporal para evitar fuga de informaci칩n entre splits manteniendo el orden cronol칩gico dentro de cada uno.\n",
    "Los `ratios` son las proporciones con las que se dividir치 el dataset:\n",
    "- train: 70%\n",
    "- dev: 15%\n",
    "- test: 15%"
   ],
   "id": "cf0c11c11a32612a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Split temporal + thread-aware\n",
    "subprocess.run([sys.executable, f\"{base}/split_thread_temporal.py\",\n",
    "                \"--in-parquet\", \"src/artifacts/prep/merged.parquet\",\n",
    "                \"--out-train\", \"src/artifacts/prep/split-train.parquet\",\n",
    "                \"--out-dev\", \"src/artifacts/prep/split-dev.parquet\",\n",
    "                \"--out-test\", \"src/artifacts/prep/split-test.parquet\",\n",
    "                \"--ratios\", \"0.7\", \"0.15\", \"0.15\",\n",
    "                \"--out-meta\", \"src/artifacts/prep/split-meta.json\"\n",
    "                ], check=True)"
   ],
   "id": "4c116173457956d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### `tokenize_hf.py`\n",
    "Carga los Parquet de train/dev/test, antepone un prefijo de dominio (`<GITHUB>`, `<REDDIT>`, en este caso no porque todav칤a estoy solo con los comentarios de GH), tokeniza los textos con el tokenizador de DistilRoBERTa/RoBERTa y guarda:\n",
    "- `dataset/` (formato `save_to_disk` de HF Datasets)\n",
    "- `tokenizer/` (vocabulario + config)\n",
    "- `preprocess_meta.json` (tama침os, `max_len`, pesos de cada clase)\n",
    "\n",
    "#### Par치metros\n",
    "- `--base-model`: modelo que se utilizar치, en este caso distilroberta\n",
    "- `--max-len 384`: longitud de secuencia; bajar acelera, subir captura m치s contexto.\n",
    "- `--use-domain-prefix`: etiqueta de la fuente (GITHUB/REDDIT)\n",
    "- `--sliding-window --slide-stride 128`: para textos muy largos (menos truncado)"
   ],
   "id": "4e94cb88fd74d42c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Para decidir el `--max-len` y la posibilidad de utilizar `--sliding-window`, se puede calcular la distribuci칩n de longitudes en tokens y elegir el valor del argumento para cubrir el *p90-p95* y obtener un mejor resultado.",
   "id": "d17eb874affc5ab"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(\"distilroberta-base\", use_fast=True)\n",
    "df = pd.read_parquet(\"../src/artifacts/prep/merged.parquet\") # o split_train.parquet\n",
    "lens = df[\"text\"].astype(str).map(lambda s: len(tok(s, truncation=False)[\"input_ids\"]))\n",
    "\n",
    "print(pd.Series(lens).describe(percentiles=[.5, .9, .95, .99]))"
   ],
   "id": "ae2900843d1dbb0d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# tokenizaci칩n HF (DistilRoBERTa/RoBERTa)\n",
    "subprocess.run([sys.executable, f\"{base}/tokenize_hf.py\",\n",
    "                \"--train-parquet\", \"src/artifacts/prep/split-train.parquet\",\n",
    "                \"--dev-parquet\", \"src/artifacts/prep/split-dev.parquet\",\n",
    "                \"--test-parquet\", \"src/artifacts/prep/split-test.parquet\",\n",
    "                \"--out-dir\", \"src/artifacts/hf_distilroberta\",\n",
    "                \"--base-model\", \"distilroberta-base\",\n",
    "                \"--max-len\", \"384\"#,\n",
    "                #\"--use-domain-prefix\", # Comentado por ahora que solo hay GH\n",
    "                ], check=True)"
   ],
   "id": "b048947f75cfae36"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
