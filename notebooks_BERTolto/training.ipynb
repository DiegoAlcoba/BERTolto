{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14e819c4",
   "metadata": {},
   "source": [
    "# COMPROBACIONES PREVIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa5ac278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PY: /opt/venv/bin/python\n",
      "CWD: /workspace/BERTolto/notebooks_BERTolto\n",
      "torch: 2.7.1+rocm7.0.0.git698b58a9  HIP: 7.0.51831-a3e329ad8  CUDA: None\n",
      "GPU?  True\n",
      "\n",
      "/dev/kfd exists? True\n",
      "/dev/dri/renderD128 exists? True\n",
      "\n",
      "site-packages: /opt/venv/lib/python3.12/site-packages\n"
     ]
    }
   ],
   "source": [
    "import os, sys, torch, subprocess, json\n",
    "print(\"PY:\", sys.executable)\n",
    "print(\"CWD:\", os.getcwd())\n",
    "print(\"torch:\", torch.__version__, \" HIP:\", getattr(torch.version, \"hip\", None), \" CUDA:\", getattr(torch.version, \"cuda\", None))\n",
    "print(\"GPU? \", torch.cuda.is_available())\n",
    "\n",
    "# ¿Existen los dispositivos GPU?\n",
    "print(\"\\n/dev/kfd exists?\", os.path.exists(\"/dev/kfd\"))\n",
    "print(\"/dev/dri/renderD128 exists?\", os.path.exists(\"/dev/dri/renderD128\"))\n",
    "\n",
    "# ¿Estoy en el venv correcto?\n",
    "print(\"\\nsite-packages:\", next(p for p in sys.path if p.endswith(\"site-packages\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7300d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.12/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU? True 7.0.51831-a3e329ad8\n",
      "AMD Radeon RX 7800 XT\n",
      "HF_HOME: /workspace/BERTolto/.hf_home\n"
     ]
    }
   ],
   "source": [
    "import torch, os, transformers\n",
    "print(\"GPU?\", torch.cuda.is_available(), getattr(torch.version, \"hip\", None))\n",
    "if torch.cuda.is_available(): print(torch.cuda.get_device_name(0))\n",
    "print(\"HF_HOME:\", os.environ.get(\"HF_HOME\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2905e69",
   "metadata": {},
   "source": [
    "# --- Bootstrap mínimo para entorno local / Docker ROCm ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc86038d54c2a122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: /workspace/BERTolto\n",
      "DEST: /workspace/BERTolto\n",
      "HF_HOME               = /workspace/BERTolto/.cache/huggingface\n",
      "HUGGINGFACE_HUB_CACHE = /workspace/BERTolto/.cache/huggingface\n",
      "TRANSFORMERS_CACHE    = /workspace/BERTolto/.cache/huggingface/hub\n",
      "OUT_DIR: /checkpoints/run_distilroberta_20251030-200801\n",
      "SAVE_DIR: /checkpoints/model_distilroberta_ft_20251030-200801\n",
      "Artifacts OK: /workspace/BERTolto/src/artifacts/hf_distilroberta\n",
      "Punteros 'latest' actualizados.\n"
     ]
    }
   ],
   "source": [
    "# === BOOTSTRAP (actualizado con versionado limpio) ===\n",
    "import os, sys, time\n",
    "from pathlib import Path\n",
    "\n",
    "# 1) Detecta entorno y fija PROJECT_ROOT\n",
    "if Path(\"/workspace/BERTolto\").exists():\n",
    "    PROJECT_ROOT = Path(\"/workspace/BERTolto\")   # dentro del contenedor\n",
    "else:\n",
    "    PROJECT_ROOT = Path(\"/home/diego/BERTolto\")  # host Ubuntu (ajusta si cambias usuario)\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "\n",
    "if Path(\"/workspace/BERTolto\").exists():\n",
    "    DEST = Path(\"/workspace/BERTolto\")\n",
    "else:\n",
    "    DEST = Path(\"/home/diego/BERTolto\")\n",
    "print(\"DEST:\", DEST)\n",
    "\n",
    "# 2) Rutas clave del repo\n",
    "SRC_DIR   = PROJECT_ROOT / \"src\"\n",
    "BASE_ARTI = SRC_DIR / \"artifacts\" / \"hf_distilroberta\"   # dataset/ y tokenizer/ viven aquí\n",
    "TMP_DIR   = PROJECT_ROOT / \"tmp\"                         # temporal local si lo necesitas\n",
    "\n",
    "# 2.1) RUN_ID y versionado de salidas\n",
    "RUN_ID   = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "CKPT_ROOT = Path(\"/checkpoints\")                         # volumen persistente montado por Docker\n",
    "\n",
    "#from datetime import datetime\n",
    "#RUN_TAG = datetime.now().strftime(\"%Y%m%d-%H%M%S\")  # o algo como \"iter01_github\"\n",
    "#OUT_DIR = f\"/checkpoints/runs/{RUN_TAG}\"\n",
    "#SAVE_DIR = f\"/checkpoints/models/{RUN_TAG}\"\n",
    "\n",
    "OUT_DIR   = CKPT_ROOT / f\"run_distilroberta_{RUN_ID}\"    # checkpoints del Trainer\n",
    "SAVE_DIR  = CKPT_ROOT / f\"model_distilroberta_ft_{RUN_ID}\"  # modelo final + threshold\n",
    "\n",
    "# (Opcional) punteros \"latest\" para encontrar fácilmente el último run\n",
    "LATEST_OUT  = CKPT_ROOT / \"run_distilroberta_latest\"\n",
    "LATEST_SAVE = CKPT_ROOT / \"model_distilroberta_ft_latest\"\n",
    "\n",
    "# 3) HF cache: UNA única ubicación y 3 variables apuntando al mismo sitio\n",
    "def _is_writable(p: Path) -> bool:\n",
    "    try:\n",
    "        p.mkdir(parents=True, exist_ok=True)\n",
    "        t = p / \".writetest\"\n",
    "        t.write_text(\"ok\", encoding=\"utf-8\")\n",
    "        t.unlink(missing_ok=True)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "# Preferimos una cache dentro del proyecto (evita permisos raros)\n",
    "HF_CACHE = (PROJECT_ROOT / \".cache\" / \"huggingface\").resolve()\n",
    "if not _is_writable(HF_CACHE):\n",
    "    # Fallback: si por lo que sea no es escribible, usa el HOME del contenedor/host\n",
    "    HF_CACHE = (Path.home() / \".cache\" / \"huggingface\").resolve()\n",
    "\n",
    "os.environ[\"HF_HOME\"] = str(HF_CACHE)\n",
    "os.environ[\"HUGGINGFACE_HUB_CACHE\"] = str(HF_CACHE)\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = str(HF_CACHE / \"hub\")\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"HF_HUB_DISABLE_TELEMETRY\"] = \"1\"\n",
    "\n",
    "# Crear carpetas necesarias\n",
    "for p in [OUT_DIR, SAVE_DIR, TMP_DIR, HF_CACHE, HF_CACHE / \"hub\"]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"HF_HOME               =\", os.environ[\"HF_HOME\"])\n",
    "print(\"HUGGINGFACE_HUB_CACHE =\", os.environ[\"HUGGINGFACE_HUB_CACHE\"])\n",
    "print(\"TRANSFORMERS_CACHE    =\", os.environ[\"TRANSFORMERS_CACHE\"])\n",
    "print(\"OUT_DIR:\", OUT_DIR)\n",
    "print(\"SAVE_DIR:\", SAVE_DIR)\n",
    "\n",
    "# 4) Asegurar que 'src/' está en el path\n",
    "if str(SRC_DIR) not in sys.path:\n",
    "    sys.path.append(str(SRC_DIR))\n",
    "\n",
    "# 5) Verificaciones rápidas de artifacts\n",
    "assert (BASE_ARTI / \"dataset\").exists(), f\"Falta dataset en {BASE_ARTI/'dataset'}\"\n",
    "assert (BASE_ARTI / \"tokenizer\").exists(), f\"Falta tokenizer en {BASE_ARTI/'tokenizer'}\"\n",
    "print(\"Artifacts OK:\", BASE_ARTI)\n",
    "\n",
    "# 6) (Opcional) refrescar punteros \"latest\" a este RUN_ID\n",
    "try:\n",
    "    for link, target in [(LATEST_OUT, OUT_DIR), (LATEST_SAVE, SAVE_DIR)]:\n",
    "        if link.exists() or link.is_symlink():\n",
    "            link.unlink()\n",
    "        link.symlink_to(target, target_is_directory=True)\n",
    "    print(\"Punteros 'latest' actualizados.\")\n",
    "except Exception as e:\n",
    "    print(\"No se pudieron crear symlinks 'latest' (no crítico):\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76013a4ff1edfeda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo listo en: /workspace/BERTolto\n"
     ]
    }
   ],
   "source": [
    "# (Local) Repo ya presente: no clonamos ni hacemos pull aquí.\n",
    "# Usamos DEST definido en la celda Bootstrap.\n",
    "from pathlib import Path\n",
    "\n",
    "assert 'DEST' in globals(), \"Asegúrate de ejecutar primero la celda Bootstrap que define DEST.\"\n",
    "assert (DEST / \"src\").exists(), f\"No se encontró src/ en {DEST}. Revisa tu ruta de trabajo o el montaje del volumen.\"\n",
    "\n",
    "print(\"Repo listo en:\", DEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a96f5aa",
   "metadata": {},
   "source": [
    "# === Visualización: helpers + callback en vivo === (Métricas)\n",
    "Define un callback que escucha los logs del Trainer y dibuja loss y F1 de validación a medida que avanza. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34f1fcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, math\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output, display\n",
    "from transformers import TrainerCallback\n",
    "\n",
    "plt.rcParams.update({\"figure.figsize\": (6,4), \"axes.grid\": True})\n",
    "\n",
    "class LivePlotCallback(TrainerCallback):\n",
    "    \"\"\"\n",
    "    Dibuja durante el entrenamiento:\n",
    "      - training_loss (de logs)\n",
    "      - métrica de validación por epoch (macro_f1 o la que elijas)\n",
    "    \"\"\"\n",
    "    def __init__(self, key=\"eval_macro_f1\"):\n",
    "        self.key = key\n",
    "        self.steps, self.train_loss = [], []\n",
    "        self.epochs, self.eval_metric = [], []\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if not logs:\n",
    "            return\n",
    "        if \"loss\" in logs and \"step\" in logs:\n",
    "            self.steps.append(state.global_step)\n",
    "            self.train_loss.append(logs[\"loss\"])\n",
    "        if self.key in logs and \"epoch\" in logs:\n",
    "            self.epochs.append(int(logs[\"epoch\"]))\n",
    "            self.eval_metric.append(logs[self.key])\n",
    "        if len(self.steps) % 10 == 0 or self.key in logs:\n",
    "            clear_output(wait=True)\n",
    "            fig, axs = plt.subplots(1, 2, figsize=(12,4))\n",
    "            axs[0].plot(self.steps, self.train_loss, marker=\".\")\n",
    "            axs[0].set_title(\"Training loss\")\n",
    "            axs[0].set_xlabel(\"global_step\"); axs[0].set_ylabel(\"loss\")\n",
    "            if self.eval_metric:\n",
    "                axs[1].plot(self.epochs, self.eval_metric, marker=\"o\")\n",
    "            axs[1].set_title(self.key)\n",
    "            axs[1].set_xlabel(\"epoch\"); axs[1].set_ylabel(self.key)\n",
    "            plt.tight_layout(); display(fig); plt.close(fig)\n",
    "\n",
    "live_cb = LivePlotCallback(key=\"eval_security_f1\")  # o \"eval_security_f1\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b8827a",
   "metadata": {},
   "source": [
    "# Preparación de artifacts locales (entorno Docker+ROCm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3091ac2d262d9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts en: /workspace/BERTolto/src/artifacts/hf_distilroberta\n",
      "Contenido: ['dataset', 'preprocess_meta.json', 'tokenizer']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Evita cargar TensorFlow por accidente (no lo usamos aquí)\n",
    "assert \"tensorflow\" not in sys.modules, \"TensorFlow está importado; desactívalo.\"\n",
    "\n",
    "# Usamos DEST de la celda Bootstrap como raíz del repo\n",
    "assert 'DEST' in globals(), \"Ejecuta primero la celda Bootstrap (define DEST).\"\n",
    "REPO_ROOT = DEST\n",
    "\n",
    "# Ruta local donde ya están los artifacts descomprimidos en tu repo:\n",
    "BASE_ARTI = REPO_ROOT / \"src\" / \"artifacts\" / \"hf_distilroberta\"\n",
    "\n",
    "# Valida que existan dataset/ y tokenizer/\n",
    "assert (BASE_ARTI / \"dataset\").exists(), f\"Falta {BASE_ARTI/'dataset'}\"\n",
    "assert (BASE_ARTI / \"tokenizer\").exists(), f\"Falta {BASE_ARTI/'tokenizer'}\"\n",
    "\n",
    "print(\"Artifacts en:\", BASE_ARTI)\n",
    "print(\"Contenido:\", sorted(p.name for p in BASE_ARTI.iterdir()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8739ca5",
   "metadata": {},
   "source": [
    "## Verificación ligera del stack (sin instalaciones en el notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b93f6ff707a83e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stack de librerías: {'transformers': '4.57.1', 'datasets': '4.2.0', 'accelerate': '1.10.1', 'huggingface_hub': '0.35.3', 'tokenizers': '0.22.1', 'evaluate': None, 'peft': '0.17.1', 'scikit-learn': '1.7.2'}\n",
      "OK. Continúa con la celda de entrenamiento.\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version as _ver, PackageNotFoundError\n",
    "\n",
    "def v(pkg):\n",
    "    try:\n",
    "        return _ver(pkg)\n",
    "    except PackageNotFoundError:\n",
    "        return None\n",
    "\n",
    "print(\"Stack de librerías:\", {\n",
    "    \"transformers\": v(\"transformers\"),\n",
    "    \"datasets\": v(\"datasets\"),\n",
    "    \"accelerate\": v(\"accelerate\"),\n",
    "    \"huggingface_hub\": v(\"huggingface_hub\"),\n",
    "    \"tokenizers\": v(\"tokenizers\"),\n",
    "    \"evaluate\": v(\"evaluate\"),\n",
    "    \"peft\": v(\"peft\"),\n",
    "    \"scikit-learn\": v(\"scikit-learn\"),\n",
    "})\n",
    "print(\"OK. Continúa con la celda de entrenamiento.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12efe72b",
   "metadata": {},
   "source": [
    "# ENTRENAMIENTO DEL MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "666bc2bae3b3090f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at inline_container.cc:659] . unexpected pos 472459840 vs 472459728",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/opt/venv/lib/python3.12/site-packages/torch/serialization.py:965\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m--> 965\u001b[0m     \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_disable_byteorder_record\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    972\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/opt/venv/lib/python3.12/site-packages/torch/serialization.py:1266\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m   1265\u001b[0m \u001b[38;5;66;03m# Now that it is on the CPU we can directly copy it into the zip file\u001b[39;00m\n\u001b[0;32m-> 1266\u001b[0m \u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:857] . PytorchStreamWriter failed writing file data/62: file write failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 350\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EarlyStoppingCallback\n\u001b[1;32m    339\u001b[0m trainer \u001b[38;5;241m=\u001b[39m WeightedTrainer(\n\u001b[1;32m    340\u001b[0m     class_weights\u001b[38;5;241m=\u001b[39mcw,\n\u001b[1;32m    341\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel, args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    347\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[live_cb, EarlyStoppingCallback(early_stopping_patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)],\n\u001b[1;32m    348\u001b[0m )\n\u001b[0;32m--> 350\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m== Eval (validation) justo tras entrenamiento ==\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    353\u001b[0m metrics_val \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate(eval_dataset\u001b[38;5;241m=\u001b[39mds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m/opt/venv/lib/python3.12/site-packages/transformers/trainer.py:2325\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/venv/lib/python3.12/site-packages/transformers/trainer.py:2790\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2787\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_training_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2789\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_epoch_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 2790\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\n\u001b[1;32m   2792\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2794\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DebugOption\u001b[38;5;241m.\u001b[39mTPU_METRICS_DEBUG \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdebug:\n\u001b[1;32m   2795\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_xla_available():\n\u001b[1;32m   2796\u001b[0m         \u001b[38;5;66;03m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/venv/lib/python3.12/site-packages/transformers/trainer.py:3228\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, learning_rate)\u001b[0m\n\u001b[1;32m   3225\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save \u001b[38;5;241m=\u001b[39m is_new_best_metric\n\u001b[1;32m   3227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[0;32m-> 3228\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3229\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_save(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m/opt/venv/lib/python3.12/site-packages/transformers/trainer.py:3345\u001b[0m, in \u001b[0;36mTrainer._save_checkpoint\u001b[0;34m(self, model, trial)\u001b[0m\n\u001b[1;32m   3341\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mbest_model_checkpoint \u001b[38;5;241m=\u001b[39m best_checkpoint_dir\n\u001b[1;32m   3343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msave_only_model:\n\u001b[1;32m   3344\u001b[0m     \u001b[38;5;66;03m# Save optimizer and scheduler\u001b[39;00m\n\u001b[0;32m-> 3345\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_optimizer_and_scheduler\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3346\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_scaler(output_dir)\n\u001b[1;32m   3347\u001b[0m     \u001b[38;5;66;03m# Save RNG state\u001b[39;00m\n",
      "File \u001b[0;32m/opt/venv/lib/python3.12/site-packages/transformers/trainer.py:3472\u001b[0m, in \u001b[0;36mTrainer._save_optimizer_and_scheduler\u001b[0;34m(self, output_dir)\u001b[0m\n\u001b[1;32m   3467\u001b[0m     save_fsdp_optimizer(\n\u001b[1;32m   3468\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfsdp_plugin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, output_dir\n\u001b[1;32m   3469\u001b[0m     )\n\u001b[1;32m   3470\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[1;32m   3471\u001b[0m     \u001b[38;5;66;03m# deepspeed.save_checkpoint above saves model/optim/sched\u001b[39;00m\n\u001b[0;32m-> 3472\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOPTIMIZER_NAME\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3474\u001b[0m \u001b[38;5;66;03m# Save SCHEDULER & SCALER\u001b[39;00m\n\u001b[1;32m   3475\u001b[0m is_deepspeed_custom_scheduler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_deepspeed_enabled \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m   3476\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler, DeepSpeedSchedulerWrapper\n\u001b[1;32m   3477\u001b[0m )\n",
      "File \u001b[0;32m/opt/venv/lib/python3.12/site-packages/torch/serialization.py:964\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    961\u001b[0m     f \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(f)\n\u001b[1;32m    963\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 964\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m            \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_disable_byteorder_record\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\n",
      "File \u001b[0;32m/opt/venv/lib/python3.12/site-packages/torch/serialization.py:798\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 798\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_like\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_end_of_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:659] . unexpected pos 472459840 vs 472459728"
     ]
    }
   ],
   "source": [
    "#*** Carga dataset tokenizado y fine-tuning supervisado de DistilRoBERTa (binario 0/1) ***#\n",
    "from pathlib import Path\n",
    "import json, sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import load_from_disk\n",
    "\n",
    "# Asegura que no quede una versión previa de transformers en memoria\n",
    "sys.modules.pop(\"transformers\", None)\n",
    "\n",
    "import transformers  # import base primero para fijar versión en sys.modules\n",
    "print(\"Transformers version:\", transformers.__version__)\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoConfig, AutoModelForSequenceClassification,\n",
    "    TrainingArguments, Trainer, DataCollatorWithPadding, set_seed\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Directorio de salida (volumen persistente montado por Docker)\n",
    "#OUT_DIR = \"/checkpoints/run_distilroberta\" -> Ya se define en bootstrap\n",
    "\n",
    "# Localiza los artifacts\n",
    "# Reutiliza BASE_ARTI definido en la celda anterior; si no, usa ruta del repo\n",
    "if \"BASE_ARTI\" in globals():\n",
    "    BASE_ARTI = Path(BASE_ARTI)\n",
    "else:\n",
    "    assert 'DEST' in globals(), \"Ejecuta la celda Bootstrap para definir DEST.\"\n",
    "    BASE_ARTI = DEST / \"src\" / \"artifacts\" / \"hf_distilroberta\"\n",
    "\n",
    "# Si hubo anidamiento tipo hf_distilroberta/hf_distilroberta, corrige\n",
    "if not (BASE_ARTI / \"dataset\").exists() and (BASE_ARTI / \"hf_distilroberta\").exists():\n",
    "    BASE_ARTI = BASE_ARTI / \"hf_distilroberta\"\n",
    "\n",
    "assert (BASE_ARTI / \"dataset\").exists() and (BASE_ARTI / \"tokenizer\").exists(), \\\n",
    "    f\"Faltan dataset/ o tokenizer/ en {BASE_ARTI}. Revisa la celda de preparación de artifacts.\"\n",
    "print(\"OK artifacts:\", BASE_ARTI)\n",
    "\n",
    "# Dispositivo y GPU info (ROCm)\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"GPU disponible:\", torch.cuda.is_available(), \"| HIP:\", getattr(torch.version, \"hip\", None))\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Device 0:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# --- PARCHE ROBUSTO V2 para carga desde disk con datasets==4.x ---\n",
    "# Idempotente y sin recursión. Evita fallos al reconstruir `features` de DatasetInfo.\n",
    "import datasets\n",
    "\n",
    "DI = datasets.info.DatasetInfo\n",
    "Feat = datasets.Features\n",
    "\n",
    "# 1) Parchea from_dict una sola vez: si las features del JSON fallan, las ignora (None)\n",
    "if not hasattr(DI, \"_orig_from_dict\"):\n",
    "    DI._orig_from_dict = DI.from_dict\n",
    "\n",
    "    @classmethod\n",
    "    def _safe_from_dict(cls, dataset_info_dict: dict):\n",
    "        try:\n",
    "            return cls._orig_from_dict(dataset_info_dict)\n",
    "        except Exception as e:\n",
    "            dd = dict(dataset_info_dict or {})\n",
    "            if \"features\" in dd:\n",
    "                dd[\"features\"] = None\n",
    "            obj = cls._orig_from_dict(dd)\n",
    "            print(\"[patch] DatasetInfo.from_dict: ignorando 'features' corruptas -> usando None.\", f\"({type(e).__name__})\")\n",
    "            return obj\n",
    "\n",
    "    DI.from_dict = _safe_from_dict\n",
    "\n",
    "# 2) Sustituye __post_init__ por una versión NO recursiva y segura (una sola vez)\n",
    "if not hasattr(DI, \"_post_init_patched\"):\n",
    "    def _safe_post_init(self):\n",
    "        try:\n",
    "            f = getattr(self, \"features\", None)\n",
    "            if f is not None and not isinstance(f, Feat):\n",
    "                try:\n",
    "                    self.features = Feat.from_dict(f)\n",
    "                except Exception:\n",
    "                    self.features = None\n",
    "        except Exception:\n",
    "            self.features = None\n",
    "        # No llamamos al __post_init__ original\n",
    "\n",
    "    DI.__post_init__ = _safe_post_init\n",
    "    DI._post_init_patched = True\n",
    "# --- FIN PARCHE ROBUSTO V2 ---\n",
    "\n",
    "# dataset/tokenizer\n",
    "ds  = load_from_disk(str(BASE_ARTI / \"dataset\"))\n",
    "\n",
    "## Comprobación de splits + fallback opcional\n",
    "print(\"Splits disponibles:\", list(ds.keys()))\n",
    "needed = {\"train\", \"validation\", \"test\"}\n",
    "avail = set(ds.keys())\n",
    "\n",
    "## Si por accidente el split se llama \"dev\", lo renombramos a \"validation\"\n",
    "if \"validation\" not in avail and \"dev\" in avail:\n",
    "    ds[\"validation\"] = ds[\"dev\"]\n",
    "    del ds[\"dev\"]\n",
    "    avail = set(ds.keys())\n",
    "    print(\"Renombrado 'dev' -> 'validation'\")\n",
    "\n",
    "## Si faltan splits, corta con mensaje claro\n",
    "missing = needed - avail\n",
    "assert not missing, f\"Faltan splits: {missing}. Revisa el paso de tokenización/guardado.\"\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(str(BASE_ARTI / \"tokenizer\"), use_fast=True)\n",
    "\n",
    "# === Multiclase: lee mapping real desde preprocess_meta.json\n",
    "meta = json.loads((BASE_ARTI / \"preprocess_meta.json\").read_text())\n",
    "label2id = {k:int(v) for k,v in meta[\"label_to_id\"].items()}\n",
    "id2label = {int(k):v for k,v in meta[\"id_to_label\"].items()}\n",
    "num_labels = len(label2id)  # 3 clases: bug/other/security\n",
    "SEC_ID = label2id.get(\"security\", 2)\n",
    "\n",
    "# Unificar columna y tipar labels a enteros\n",
    "from datasets import ClassLabel\n",
    "\n",
    "# 1) Renombra si viniera como \"label\"\n",
    "if \"label\" in ds[\"train\"].column_names and \"labels\" not in ds[\"train\"].column_names:\n",
    "    ds = ds.rename_column(\"label\", \"labels\")\n",
    "\n",
    "# 2) Mapea strings -> ids o fuerza a int si ya vinieran numéricas\n",
    "def _labels_to_ids(batch):\n",
    "    vals = batch[\"labels\"]\n",
    "    if isinstance(vals[0], str):\n",
    "        batch[\"labels\"] = [label2id[v] for v in vals]\n",
    "    else:\n",
    "        batch[\"labels\"] = [int(v) for v in vals]\n",
    "    return batch\n",
    "\n",
    "ds = ds.map(_labels_to_ids, batched=True)\n",
    "\n",
    "# 3) (Opcional pero recomendable) Fijar esquema explícito con nombres\n",
    "label_names = [id2label[i] for i in range(num_labels)]\n",
    "ds = ds.cast_column(\"labels\", ClassLabel(num_classes=num_labels, names=label_names))\n",
    "\n",
    "print(ds[\"train\"].features)\n",
    "\n",
    "\n",
    "# métricas macro + foco en \"security vs resto\"\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(axis=1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    p_macro, r_macro, f1_macro, _ = precision_recall_fscore_support(\n",
    "        labels, preds, average=\"macro\", zero_division=0\n",
    "    )\n",
    "    y_true_sec = (labels == SEC_ID).astype(int)\n",
    "    y_pred_sec = (preds  == SEC_ID).astype(int)\n",
    "    p_sec, r_sec, f1_sec, _ = precision_recall_fscore_support(\n",
    "        y_true_sec, y_pred_sec, average=\"binary\", zero_division=0\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"macro_precision\": p_macro, \"macro_recall\": r_macro, \"macro_f1\": f1_macro,\n",
    "        \"security_precision\": p_sec, \"security_recall\": r_sec, \"security_f1\": f1_sec,\n",
    "    }\n",
    "\n",
    "# class weights (longitud = num_labels)\n",
    "cw = None\n",
    "\n",
    "if \"class_weights\" in meta and isinstance(meta[\"class_weights\"], dict):\n",
    "    cw_map = {int(k): float(v) for k, v in meta[\"class_weights\"].items()}\n",
    "    cw = np.array([cw_map.get(i, 1.0) for i in range(num_labels)], dtype=np.float32)\n",
    "    print(\"Class weights:\", cw.tolist())\n",
    "\n",
    "# Comprobación de la ruta\n",
    "import os\n",
    "print(\"HF_HOME =\", os.environ.get(\"HF_HOME\"))\n",
    "print(\"HUGGINGFACE_HUB_CACHE =\", os.environ.get(\"HUGGINGFACE_HUB_CACHE\"))\n",
    "print(\"TRANSFORMERS_CACHE =\", os.environ.get(\"TRANSFORMERS_CACHE\"))\n",
    "##\n",
    "\n",
    "# Config para el modelo distilrobeta-base utilizando el mapeo real de labels disponible en preprocess_meta.json\n",
    "config = AutoConfig.from_pretrained(\n",
    "    \"distilroberta-base\",\n",
    "    num_labels=num_labels,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "model  = AutoModelForSequenceClassification.from_pretrained(\"distilroberta-base\", config=config)\n",
    "\n",
    "# Collator que ignora claves no usadas por el modelo y añade labels aparte\n",
    "class SafeCollator(DataCollatorWithPadding):\n",
    "    def __call__(self, features):\n",
    "        # recoge labels (acepta 'labels' o 'label')\n",
    "        labels = []\n",
    "        cleaned = []\n",
    "        for f in features:\n",
    "            if \"labels\" in f:\n",
    "                labels.append(f[\"labels\"])\n",
    "            elif \"label\" in f:\n",
    "                labels.append(f[\"label\"])\n",
    "            # solo claves esperadas por el modelo\n",
    "            nf = {}\n",
    "            for k in (\"input_ids\", \"attention_mask\", \"token_type_ids\"):\n",
    "                if k in f:\n",
    "                    nf[k] = f[k]\n",
    "            cleaned.append(nf)\n",
    "\n",
    "        batch = self.tokenizer.pad(cleaned, padding=True, return_tensors=\"pt\")\n",
    "        if labels:\n",
    "            batch[\"labels\"] = torch.tensor(labels, dtype=torch.long)\n",
    "        return batch\n",
    "\n",
    "collator = SafeCollator(tokenizer=tok, return_tensors=\"pt\")\n",
    "\n",
    "# Trainer con pérdida ponderada (si hay weights) y filtrado de inputs\n",
    "class WeightedTrainer(Trainer):\n",
    "    def __init__(self, class_weights=None, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.class_weights = (\n",
    "            torch.tensor(class_weights, dtype=torch.float32) if class_weights is not None else None\n",
    "        )\n",
    "\n",
    "    # En Transformers 4.56.x, Trainer pasa num_items_in_batch; lo aceptamos e ignoramos.\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        # Acepta 'labels' o 'label'\n",
    "        labels = inputs.pop(\"labels\", None)\n",
    "        if labels is None and \"label\" in inputs:\n",
    "            labels = inputs.pop(\"label\")\n",
    "        if labels is None:\n",
    "            raise ValueError(\"Missing 'labels' in inputs\")\n",
    "\n",
    "        # Filtra claves inesperadas (evita pasar id/context_id al modelo)\n",
    "        allowed = {\"input_ids\", \"attention_mask\", \"token_type_ids\"}\n",
    "        model_inputs = {k: v for k, v in inputs.items() if k in allowed}\n",
    "\n",
    "        outputs = model(**model_inputs)\n",
    "        logits = outputs.logits  # [B, 2]\n",
    "\n",
    "        # CrossEntropy con o sin pesos\n",
    "        if self.class_weights is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss(weight=self.class_weights.to(logits.device))\n",
    "        else:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "\n",
    "        loss = loss_fct(logits.view(-1, logits.size(-1)), labels.view(-1).long())\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "# --- TrainingArguments (compatible 4.x) ---\n",
    "from inspect import signature\n",
    "\n",
    "TA = TrainingArguments\n",
    "ta_params = set(signature(TA).parameters.keys())\n",
    "\n",
    "# Compat: algunas versiones usan 'eval_strategy' en vez de 'evaluation_strategy'\n",
    "has_evaluation_strategy = \"evaluation_strategy\" in ta_params\n",
    "has_eval_strategy = \"eval_strategy\" in ta_params\n",
    "\n",
    "# 'report_to' en versiones recientes debe ser lista (no string)\n",
    "report_to_val = []  # equivalente a \"none\"\n",
    "\n",
    "# Mezcla de precisión óptima en ROCm (usa bf16 si está soportado, si no fp16)\n",
    "use_bf16 = torch.cuda.is_available() and torch.cuda.is_bf16_supported()\n",
    "use_fp16 = torch.cuda.is_available() and not use_bf16\n",
    "\n",
    "# Opcional: algo de ahorro de VRAM con gradient checkpointing\n",
    "# (si notas el entrenamiento muy justo de VRAM, ponlo a True)\n",
    "gradient_checkpointing = False\n",
    "\n",
    "# Algo de rendimiento en matmul (no afecta a la reproducibilidad exacta)\n",
    "try:\n",
    "    torch.set_float32_matmul_precision(\"high\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "\n",
    "ta_kwargs = dict(\n",
    "    output_dir=OUT_DIR,\n",
    "    # Logging/eval/guardar por época: suficiente para tu workflow y ligero\n",
    "    save_strategy=\"epoch\",\n",
    "    #evaluation_strategy=\"epoch\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=50,\n",
    "\n",
    "    # Núcleo de entrenamiento\n",
    "    per_device_train_batch_size=16,   # efectivo 32 con grad_accum, ver abajo\n",
    "    per_device_eval_batch_size=32,    # eval cabe bien con 16 GB VRAM\n",
    "    gradient_accumulation_steps=2,    # efectivo 32 -> estable y rápido\n",
    "    num_train_epochs=3,               # sube a 4 si quieres exprimir un poco más\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    max_grad_norm=1.0,\n",
    "\n",
    "    # Precisión mixta en ROCm\n",
    "    bf16=use_bf16,\n",
    "    fp16=use_fp16,\n",
    "\n",
    "    # Optimizador/planificador robustos\n",
    "    optim=\"adamw_torch\",\n",
    "    lr_scheduler_type=\"cosine\",       # suave; alternativa: \"linear\"\n",
    "\n",
    "    # Rendimiento DataLoader\n",
    "    dataloader_num_workers=4,         # súbelo a 6–8 si el disco da de sí\n",
    "    dataloader_pin_memory=True,\n",
    "\n",
    "    # Infra de Trainer\n",
    "    report_to=report_to_val,\n",
    "    remove_unused_columns=False,      # mantenemos id/context_id\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"security_f1\",   #<-------- o \"security_f1\" si prefiero\n",
    "    greater_is_better=True,\n",
    "    seed=42,\n",
    "\n",
    "    # Compilación desactivada por defecto (a veces inestable en ROCm)\n",
    "    torch_compile=False,\n",
    "\n",
    "    #Si se queda corto/largo de VRAM (OOM/sobra)\n",
    "    #OOM: baja per_device_train_batch_size a 12 o 8; o pon gradient_checkpointing=True (más lento pero ahorra VRAM).\n",
    "    #Sobra VRAM y quieres apretar: sube per_device_train_batch_size a 20–24 y baja gradient_accumulation_steps a 1 (o mantén 2 para más estabilidad).\n",
    ")\n",
    "\n",
    "# Añade la estrategia de evaluación usando el nombre correcto\n",
    "if has_evaluation_strategy:\n",
    "    ta_kwargs[\"evaluation_strategy\"] = \"epoch\"\n",
    "elif has_eval_strategy:\n",
    "    ta_kwargs[\"eval_strategy\"] = \"epoch\"\n",
    "else:\n",
    "    print(\"[warn] TrainingArguments no tiene evaluation_strategy/​eval_strategy; se usará la predeterminada.\")\n",
    "\n",
    "# Activa gradient checkpointing si lo pediste arriba\n",
    "if gradient_checkpointing:\n",
    "    model.gradient_checkpointing_enable()\n",
    "\n",
    "args = TA(**ta_kwargs)\n",
    "\n",
    "from transformers import EarlyStoppingCallback\n",
    "trainer = WeightedTrainer(\n",
    "    class_weights=cw,\n",
    "    model=model, args=args,\n",
    "    train_dataset=ds[\"train\"],\n",
    "    eval_dataset=ds[\"validation\"],\n",
    "    processing_class=tok,\n",
    "    data_collator=collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[live_cb, EarlyStoppingCallback(early_stopping_patience=2)],\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "print(\"\\n== Eval (validation) justo tras entrenamiento ==\")\n",
    "metrics_val = trainer.evaluate(eval_dataset=ds[\"validation\"])\n",
    "for k, v in metrics_val.items():\n",
    "    print(f\"{k}: {v:.4f}\" if isinstance(v, (int, float)) else f\"{k}: {v}\")\n",
    "\n",
    "\n",
    "trainer.save_model(str(SAVE_DIR))\n",
    "tok.save_pretrained(str(SAVE_DIR))\n",
    "print(\"Modelo guardado en:\", SAVE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31141894",
   "metadata": {},
   "source": [
    "# === Post-entrenamiento: curvas desde logs ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07811c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curvas de entrenamiento SIN widgets (robusto en VS Code/ROCm)\n",
    "# - Funciona aunque hayas reiniciado el kernel (lee trainer_state.json)\n",
    "# - Guarda PNG y CSV con las métricas\n",
    "\n",
    "import os, json, math\n",
    "from pathlib import Path\n",
    "\n",
    "# 0) Backend no interactivo *antes* de importar pyplot\n",
    "import matplotlib as mpl\n",
    "mpl.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display\n",
    "import csv\n",
    "\n",
    "# 1) Localiza OUT_DIR y trainer_state.json\n",
    "assert 'OUT_DIR' in globals(), \"OUT_DIR no está definido (ejecuta Bootstrap/entrenamiento).\"\n",
    "OUT_DIR = Path(OUT_DIR)\n",
    "ts_path = OUT_DIR / \"trainer_state.json\"\n",
    "\n",
    "# 2) Cargar log_history (memoria o disco)\n",
    "log_history = []\n",
    "if 'trainer' in globals() and hasattr(trainer, 'state') and trainer.state.log_history:\n",
    "    log_history = trainer.state.log_history\n",
    "\n",
    "if (not log_history) and ts_path.exists():\n",
    "    with ts_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        ts = json.load(f)\n",
    "    log_history = ts.get(\"log_history\", [])\n",
    "\n",
    "print(f\"log_history registros: {len(log_history)}\")\n",
    "if not log_history:\n",
    "    print(f\"⚠️ No hay logs. ¿Se ejecutó entrenamiento? Revisar {ts_path}\")\n",
    "\n",
    "# 3) Extraer series\n",
    "steps, tr_loss = [], []\n",
    "epx, eval_f1, eval_prec, eval_rec, eval_acc = [], [], [], [], []\n",
    "lrs, lr_steps = [], []\n",
    "\n",
    "for e in log_history:\n",
    "    # loss por step (solo si se configuró logging por pasos)\n",
    "    if \"loss\" in e and \"step\" in e:\n",
    "        steps.append(e[\"step\"])\n",
    "        tr_loss.append(e[\"loss\"])\n",
    "    # lr scheduler (si se logueó)\n",
    "    if \"learning_rate\" in e and \"step\" in e:\n",
    "        lr_steps.append(e[\"step\"])\n",
    "        lrs.append(e[\"learning_rate\"])\n",
    "    # métricas de validación por epoch\n",
    "    if \"eval_macro_f1\" in e:\n",
    "        ep = e.get(\"epoch\")\n",
    "        if ep is None:\n",
    "            ep = (epx[-1] + 1) if epx else 1\n",
    "        ep = int(ep) if isinstance(ep, (int, float)) and not math.isnan(ep) else ep\n",
    "        epx.append(ep)\n",
    "        eval_f1.append(e[\"eval_macro_f1\"])\n",
    "        #eval_prec.append(e.get(\"eval_precision\", float(\"nan\")))\n",
    "        #eval_rec.append(e.get(\"eval_recall\", float(\"nan\")))\n",
    "        #eval_acc.append(e.get(\"eval_accuracy\", float(\"nan\")))\n",
    "\n",
    "# 4) Dibujar y guardar PNG\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# (A) Training loss\n",
    "axs[0].plot(steps, tr_loss, marker=\".\", linestyle=\"-\")\n",
    "axs[0].set_title(\"Training loss (logs)\")\n",
    "axs[0].set_xlabel(\"global_step\"); axs[0].set_ylabel(\"loss\")\n",
    "if not steps:\n",
    "    axs[0].text(0.5, 0.5, \"Sin logs por pasos.\\nUsa logging_strategy='steps' y logging_steps.\",\n",
    "                ha=\"center\", va=\"center\", transform=axs[0].transAxes)\n",
    "\n",
    "# (B) Métricas de validación por epoch\n",
    "axs[1].plot(epx, eval_f1,   marker=\"o\", label=\"F1\")\n",
    "axs[1].plot(epx, eval_prec, marker=\"o\", label=\"Precision\")\n",
    "axs[1].plot(epx, eval_rec,  marker=\"o\", label=\"Recall\")\n",
    "axs[1].plot(epx, eval_acc,  marker=\"o\", label=\"Accuracy\")\n",
    "axs[1].set_title(\"Métricas de validación por época\")\n",
    "axs[1].set_xlabel(\"epoch\"); axs[1].legend()\n",
    "if not epx:\n",
    "    axs[1].text(0.5, 0.5, \"Sin métricas de validación.\\n¿evaluation_strategy='epoch'?\",\n",
    "                ha=\"center\", va=\"center\", transform=axs[1].transAxes)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# 5) Salvar figuras/CSV en el repo\n",
    "FIG_DIR = Path.cwd() / \"figs\"\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "png_path = FIG_DIR / \"training_curves.png\"\n",
    "plt.savefig(png_path, dpi=150, bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "\n",
    "# CSV con métricas por epoch (si existen)\n",
    "csv_path = FIG_DIR / \"validation_metrics_by_epoch.csv\"\n",
    "if epx:\n",
    "    with csv_path.open(\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow([\"epoch\", \"f1\", \"precision\", \"recall\", \"accuracy\"])\n",
    "        for i in range(len(epx)):\n",
    "            w.writerow([epx[i], eval_f1[i], eval_prec[i], eval_rec[i], eval_acc[i]])\n",
    "\n",
    "print(\"Figura guardada en:\", png_path)\n",
    "if epx:\n",
    "    print(\"CSV guardado en:\", csv_path)\n",
    "\n",
    "display(Image(filename=str(png_path)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08bb35a",
   "metadata": {},
   "source": [
    "## Calibración autónoma desde disco (sin reentrenar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abed048bb36f0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json, numpy as np, torch\n",
    "from datasets import load_from_disk\n",
    "from transformers import (AutoTokenizer, AutoConfig, AutoModelForSequenceClassification,\n",
    "                          TrainingArguments, Trainer, DataCollatorWithPadding)\n",
    "\n",
    "# RUTAS (locales)\n",
    "if \"BASE_ARTI\" in globals():\n",
    "    BASE_ARTI = Path(BASE_ARTI)\n",
    "else:\n",
    "    assert 'DEST' in globals(), \"Ejecuta la celda Bootstrap para definir DEST.\"\n",
    "    BASE_ARTI = DEST / \"src\" / \"artifacts\" / \"hf_distilroberta\"\n",
    "\n",
    "OUT_TMP  = (DEST / \"tmp_calib\"); OUT_TMP.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 1) Dataset y tokenizer\n",
    "ds  = load_from_disk(str(BASE_ARTI / \"dataset\"))\n",
    "tok = AutoTokenizer.from_pretrained(str(BASE_ARTI / \"tokenizer\"), use_fast=True)\n",
    "\n",
    "# 2) Modelo (final)\n",
    "config = AutoConfig.from_pretrained(str(SAVE_DIR))\n",
    "model  = AutoModelForSequenceClassification.from_pretrained(str(SAVE_DIR), config=config)\n",
    "\n",
    "# 3) Trainer “ligero” solo para predict\n",
    "args = TrainingArguments(\n",
    "    output_dir=str(OUT_TMP),\n",
    "    per_device_eval_batch_size=128,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    dataloader_num_workers=2,\n",
    "    report_to=[]\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model, args=args, processing_class=tok,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tok, return_tensors=\"pt\")\n",
    ")\n",
    "\n",
    "# --- Calibración rápida (un único predict) ---\n",
    "def _prepare_pred_dataset(split):\n",
    "    d = ds[split]\n",
    "    cols = d.column_names\n",
    "    label_col = \"labels\" if \"labels\" in cols else (\"label\" if \"label\" in cols else None)\n",
    "    assert label_col is not None, f\"Split {split} sin columna de label.\"\n",
    "    keep = [\"input_ids\", \"attention_mask\", label_col] + ([\"token_type_ids\"] if \"token_type_ids\" in cols else [])\n",
    "    ids = d[\"id\"] if \"id\" in cols else list(range(len(d)))\n",
    "    ctx = d[\"context_id\"] if \"context_id\" in cols else [0] * len(d)\n",
    "    pred_ds = d.remove_columns([c for c in cols if c not in keep])\n",
    "    labels = np.array(d[label_col])\n",
    "    return pred_ds, labels, np.array(ids), np.array(ctx)\n",
    "\n",
    "def logits_labels_ids(split):\n",
    "    pred_ds, labels, ids, ctx = _prepare_pred_dataset(split)\n",
    "    logits = trainer.predict(pred_ds).predictions  # [N, 2]\n",
    "    return logits, labels, ids, ctx\n",
    "\n",
    "def softmax_np(x):\n",
    "    x = x - x.max(axis=-1, keepdims=True)\n",
    "    ex = np.exp(x)\n",
    "    return ex / ex.sum(axis=-1, keepdims=True)\n",
    "\n",
    "logits_val, labels_val, ids_val, ctx_val = logits_labels_ids(\"validation\")\n",
    "# ➜ probabilidad de \"security\"\n",
    "p1_val = softmax_np(logits_val)[:, SEC_ID]\n",
    "\n",
    "# Pooling máximo por comentario (id, context_id)\n",
    "keys = np.core.defchararray.add(ids_val.astype(str), \"::\" + ctx_val.astype(str))\n",
    "order = np.argsort(keys)\n",
    "keys_s, p1_s, y_s = keys[order], p1_val[order], labels_val[order]\n",
    "grp_st = np.r_[0, 1 + np.flatnonzero(keys_s[1:] != keys_s[:-1])]\n",
    "pooled_p1 = np.maximum.reduceat(p1_s, grp_st)\n",
    "pooled_y  = y_s[grp_st].astype(int)\n",
    "\n",
    "TARGET_PREC = 0.95  # objetivo de precisión mínima -> menos falsos positivos\n",
    "# Busca el mejor umbral que maximice recall con precision >= TARGET_PREC\n",
    "ord_desc = np.argsort(-pooled_p1)\n",
    "scores = pooled_p1[ord_desc]\n",
    "y_true = pooled_y[ord_desc]\n",
    "tp = np.cumsum(y_true); fp = np.cumsum(1 - y_true); fn_tot = y_true.sum()\n",
    "prec = tp / np.maximum(tp + fp, 1e-9)\n",
    "rec  = tp / np.maximum(fn_tot, 1e-9)\n",
    "mask = prec >= TARGET_PREC\n",
    "best_idx = int(np.argmax(rec * mask)) if np.any(mask) else int(np.argmax(prec))\n",
    "best_thr, best_prec, best_rec = float(scores[best_idx]), float(prec[best_idx]), float(rec[best_idx])\n",
    "\n",
    "(SAVE_DIR / \"threshold.json\").write_text(json.dumps({\n",
    "    \"threshold\": best_thr,\n",
    "    \"target_precision\": TARGET_PREC,\n",
    "    \"precision_at_threshold\": best_prec,\n",
    "    \"recall_at_threshold\": best_rec\n",
    "}, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "print(f\"[calibración] threshold={best_thr:.4f} | precision={best_prec:.4f} | recall={best_rec:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd154bbe",
   "metadata": {},
   "source": [
    "# === Visualización de calibración (usar variables ya calculadas) ===\n",
    "Muestra la curva PR y la distribución de puntuaciones por clase (válido para la memoria del TFG). Además guarda `val_pooled_scores.npy` y `val_pooled_labels.npy` en SAVE_DIR por si se necesita \"replotear\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb4e133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardado para reutilizar en otra sesión\n",
    "np.save(Path(SAVE_DIR, \"val_pooled_scores.npy\"), scores)     # prob. clase 1 por comentario\n",
    "np.save(Path(SAVE_DIR, \"val_pooled_labels.npy\"), y_true.astype(int))\n",
    "\n",
    "# Curva Prec-Recall (ordenando por score desc, ya lo tenemos)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(rec, prec)\n",
    "plt.scatter([best_rec], [best_prec], marker=\"o\", label=f\"thr={best_thr:.3f}\")\n",
    "plt.title(\"Precision-Recall (validación, pooling=max)\")\n",
    "plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.legend(); plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Histograma de puntuaciones\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(scores[y_true==0], bins=30, alpha=0.6, label=\"negativos\")\n",
    "plt.hist(scores[y_true==1], bins=30, alpha=0.6, label=\"positivos\")\n",
    "plt.axvline(best_thr, ls=\"--\", label=f\"threshold={best_thr:.3f}\")\n",
    "plt.title(\"Distribución de puntuaciones (pooled p1)\")\n",
    "plt.xlabel(\"p1 (pooled)\"); plt.ylabel(\"count\"); plt.legend(); plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f4f63d36449468",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluación final en TEST (pooling por comentario)\n",
    "import json, numpy as np, torch\n",
    "from pathlib import Path\n",
    "from datasets import load_from_disk\n",
    "from transformers import (AutoTokenizer, AutoConfig, AutoModelForSequenceClassification,\n",
    "                          TrainingArguments, Trainer, DataCollatorWithPadding)\n",
    "\n",
    "# Rutas\n",
    "if \"BASE_ARTI\" in globals():\n",
    "    BASE_ARTI = Path(BASE_ARTI)\n",
    "else:\n",
    "    assert 'DEST' in globals(), \"Ejecuta la celda Bootstrap para definir DEST.\"\n",
    "    BASE_ARTI = DEST / \"src\" / \"artifacts\" / \"hf_distilroberta\"\n",
    "\n",
    "thr = float(json.loads((SAVE_DIR / \"threshold.json\").read_text())[\"threshold\"])\n",
    "\n",
    "# Carga\n",
    "ds  = load_from_disk(str(BASE_ARTI / \"dataset\"))\n",
    "tok = AutoTokenizer.from_pretrained(str(BASE_ARTI / \"tokenizer\"), use_fast=True)\n",
    "config = AutoConfig.from_pretrained(str(SAVE_DIR))\n",
    "model  = AutoModelForSequenceClassification.from_pretrained(str(SAVE_DIR), config=config)\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=str(DEST / \"tmp_eval\"),\n",
    "    per_device_eval_batch_size=128,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    dataloader_num_workers=2,\n",
    "    report_to=[]\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model, args=args, processing_class=tok,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tok, return_tensors=\"pt\")\n",
    ")\n",
    "\n",
    "def _prep(split):\n",
    "    d = ds[split]; cols = d.column_names\n",
    "    label_col = \"labels\" if \"labels\" in cols else \"label\"\n",
    "    keep = [\"input_ids\",\"attention_mask\",label_col] + ([\"token_type_ids\"] if \"token_type_ids\" in cols else [])\n",
    "    ids = d[\"id\"] if \"id\" in cols else list(range(len(d)))\n",
    "    ctx = d[\"context_id\"] if \"context_id\" in cols else [0]*len(d)\n",
    "    pred_ds = d.remove_columns([c for c in cols if c not in keep])\n",
    "    labels = np.array(d[label_col])\n",
    "    return pred_ds, labels, np.array(ids), np.array(ctx)\n",
    "\n",
    "def _softmax(x): x=x-x.max(axis=-1,keepdims=True); ex=np.exp(x); return ex/ex.sum(axis=-1,keepdims=True)\n",
    "\n",
    "def _pooled(split):\n",
    "    pred_ds, labels, ids, ctx = _prep(split)\n",
    "    logits = trainer.predict(pred_ds).predictions\n",
    "    p1 = _softmax(logits)[:, SEC_ID]\n",
    "    keys = np.core.defchararray.add(ids.astype(str),\"::\"+ctx.astype(str))\n",
    "    order = np.argsort(keys); keys_s,p1_s,y_s = keys[order],p1[order],labels[order]\n",
    "    grp = np.r_[0,1+np.flatnonzero(keys_s[1:]!=keys_s[:-1])]\n",
    "    pooled_p1 = np.maximum.reduceat(p1_s, grp)\n",
    "    pooled_y  = y_s[grp].astype(int)\n",
    "    return pooled_p1, pooled_y\n",
    "\n",
    "def _metrics(split, thr):\n",
    "    scores, y_true = _pooled(split)\n",
    "    pred = (scores >= thr).astype(int)\n",
    "    tp = int(((pred==1)&(y_true==1)).sum())\n",
    "    fp = int(((pred==1)&(y_true==0)).sum())\n",
    "    fn = int(((pred==0)&(y_true==1)).sum())\n",
    "    tn = int(((pred==0)&(y_true==0)).sum())\n",
    "    prec = tp / max(tp+fp, 1e-9)\n",
    "    rec  = tp / max(tp+fn, 1e-9)\n",
    "    f1   = 2*prec*rec / max(prec+rec, 1e-9)\n",
    "    acc  = (tp+tn) / max(tp+tn+fp+fn, 1e-9)\n",
    "    return dict(precision=prec, recall=rec, f1=f1, accuracy=acc,\n",
    "                counts=dict(tp=tp, fp=fp, fn=fn, tn=tn))\n",
    "\n",
    "val_metrics  = _metrics(\"validation\", thr)\n",
    "test_metrics = _metrics(\"test\", thr)\n",
    "\n",
    "(SAVE_DIR / \"eval_comment_level.json\").write_text(\n",
    "    json.dumps({\"validation\": val_metrics, \"test\": test_metrics}, indent=2), encoding=\"utf-8\"\n",
    ")\n",
    "(SAVE_DIR / \"inference_meta.json\").write_text(\n",
    "    json.dumps({\"pooling\":\"max\", \"threshold\": float(thr)}, indent=2), encoding=\"utf-8\"\n",
    ")\n",
    "\n",
    "print(\"VAL:\", val_metrics)\n",
    "print(\"TEST:\", test_metrics)\n",
    "print(\"Guardado en:\", SAVE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34ba1b7",
   "metadata": {},
   "source": [
    "# === Matriz de confusión (valid/test) ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2749eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion(cm, title):\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.imshow(cm, interpolation=\"nearest\")\n",
    "    plt.title(title)\n",
    "    plt.xticks([0,1], [\"Pred 0\",\"Pred 1\"])\n",
    "    plt.yticks([0,1], [\"True 0\",\"True 1\"])\n",
    "    for (i,j), v in np.ndenumerate(cm):\n",
    "        plt.text(j, i, str(v), ha=\"center\", va=\"center\", color=\"white\" if v>cm.max()/2 else \"black\")\n",
    "    plt.colorbar(); plt.tight_layout(); plt.show()\n",
    "\n",
    "cm_val = np.array([[val_metrics[\"counts\"][\"tn\"], val_metrics[\"counts\"][\"fp\"]],\n",
    "                   [val_metrics[\"counts\"][\"fn\"], val_metrics[\"counts\"][\"tp\"]]])\n",
    "cm_tst = np.array([[test_metrics[\"counts\"][\"tn\"], test_metrics[\"counts\"][\"fp\"]],\n",
    "                   [test_metrics[\"counts\"][\"fn\"], test_metrics[\"counts\"][\"tp\"]]])\n",
    "\n",
    "plot_confusion(cm_val, \"Confusion Matrix (VALID)\")\n",
    "plot_confusion(cm_tst, \"Confusion Matrix (TEST)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef0f33d0ca143b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## \"Pack\" final listo para reutilizar/re-entrenar (en el propio repo)\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "DEPLOY_DIR = DEST / \"deploy_distilroberta\"\n",
    "if DEPLOY_DIR.exists():\n",
    "    shutil.rmtree(DEPLOY_DIR)\n",
    "shutil.copytree(SAVE_DIR, DEPLOY_DIR)\n",
    "print(\"Pack listo en:\", DEPLOY_DIR)\n",
    "print(\"Contenidos:\", [p.name for p in DEPLOY_DIR.iterdir()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (bertolto)",
   "language": "python",
   "name": "bertolto"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
