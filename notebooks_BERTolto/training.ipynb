{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14e819c4",
   "metadata": {},
   "source": [
    "# COMPROBACIONES PREVIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5ac278",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, torch, subprocess, json\n",
    "print(\"PY:\", sys.executable)\n",
    "print(\"CWD:\", os.getcwd())\n",
    "print(\"torch:\", torch.__version__, \" HIP:\", getattr(torch.version, \"hip\", None), \" CUDA:\", getattr(torch.version, \"cuda\", None))\n",
    "print(\"GPU? \", torch.cuda.is_available())\n",
    "\n",
    "# ¿Existen los dispositivos GPU?\n",
    "print(\"\\n/dev/kfd exists?\", os.path.exists(\"/dev/kfd\"))\n",
    "print(\"/dev/dri/renderD128 exists?\", os.path.exists(\"/dev/dri/renderD128\"))\n",
    "\n",
    "# ¿Estoy en el venv correcto?\n",
    "print(\"\\nsite-packages:\", next(p for p in sys.path if p.endswith(\"site-packages\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7300d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os, transformers\n",
    "print(\"GPU?\", torch.cuda.is_available(), getattr(torch.version, \"hip\", None))\n",
    "if torch.cuda.is_available(): print(torch.cuda.get_device_name(0))\n",
    "print(\"HF_HOME:\", os.environ.get(\"HF_HOME\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2905e69",
   "metadata": {},
   "source": [
    "# --- Bootstrap mínimo para entorno local / Docker ROCm ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc86038d54c2a122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === BOOTSTRAP (actualizado con versionado limpio) ===\n",
    "import os, sys, time\n",
    "from pathlib import Path\n",
    "\n",
    "# 1) Detecta entorno y fija PROJECT_ROOT\n",
    "if Path(\"/workspace/BERTolto\").exists():\n",
    "    PROJECT_ROOT = Path(\"/workspace/BERTolto\")   # dentro del contenedor\n",
    "else:\n",
    "    PROJECT_ROOT = Path(\"/home/diego/BERTolto\")  # host Ubuntu (ajusta si cambias usuario)\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "\n",
    "# 2) Rutas clave del repo\n",
    "SRC_DIR   = PROJECT_ROOT / \"src\"\n",
    "BASE_ARTI = SRC_DIR / \"artifacts\" / \"hf_distilroberta\"   # dataset/ y tokenizer/ viven aquí\n",
    "TMP_DIR   = PROJECT_ROOT / \"tmp\"                         # temporal local si lo necesitas\n",
    "\n",
    "# 2.1) RUN_ID y versionado de salidas\n",
    "RUN_ID   = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "CKPT_ROOT = Path(\"/checkpoints\")                         # volumen persistente montado por Docker\n",
    "\n",
    "#from datetime import datetime\n",
    "#RUN_TAG = datetime.now().strftime(\"%Y%m%d-%H%M%S\")  # o algo como \"iter01_github\"\n",
    "#OUT_DIR = f\"/checkpoints/runs/{RUN_TAG}\"\n",
    "#SAVE_DIR = f\"/checkpoints/models/{RUN_TAG}\"\n",
    "\n",
    "OUT_DIR   = CKPT_ROOT / f\"run_distilroberta_{RUN_ID}\"    # checkpoints del Trainer\n",
    "SAVE_DIR  = CKPT_ROOT / f\"model_distilroberta_ft_{RUN_ID}\"  # modelo final + threshold\n",
    "\n",
    "# (Opcional) punteros \"latest\" para encontrar fácilmente el último run\n",
    "LATEST_OUT  = CKPT_ROOT / \"run_distilroberta_latest\"\n",
    "LATEST_SAVE = CKPT_ROOT / \"model_distilroberta_ft_latest\"\n",
    "\n",
    "# 3) HF cache: UNA única ubicación y 3 variables apuntando al mismo sitio\n",
    "def _is_writable(p: Path) -> bool:\n",
    "    try:\n",
    "        p.mkdir(parents=True, exist_ok=True)\n",
    "        t = p / \".writetest\"\n",
    "        t.write_text(\"ok\", encoding=\"utf-8\")\n",
    "        t.unlink(missing_ok=True)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "# Preferimos una cache dentro del proyecto (evita permisos raros)\n",
    "HF_CACHE = (PROJECT_ROOT / \".cache\" / \"huggingface\").resolve()\n",
    "if not _is_writable(HF_CACHE):\n",
    "    # Fallback: si por lo que sea no es escribible, usa el HOME del contenedor/host\n",
    "    HF_CACHE = (Path.home() / \".cache\" / \"huggingface\").resolve()\n",
    "\n",
    "os.environ[\"HF_HOME\"] = str(HF_CACHE)\n",
    "os.environ[\"HUGGINGFACE_HUB_CACHE\"] = str(HF_CACHE)\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = str(HF_CACHE / \"hub\")\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"HF_HUB_DISABLE_TELEMETRY\"] = \"1\"\n",
    "\n",
    "# Crear carpetas necesarias\n",
    "for p in [OUT_DIR, SAVE_DIR, TMP_DIR, HF_CACHE, HF_CACHE / \"hub\"]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"HF_HOME               =\", os.environ[\"HF_HOME\"])\n",
    "print(\"HUGGINGFACE_HUB_CACHE =\", os.environ[\"HUGGINGFACE_HUB_CACHE\"])\n",
    "print(\"TRANSFORMERS_CACHE    =\", os.environ[\"TRANSFORMERS_CACHE\"])\n",
    "print(\"OUT_DIR:\", OUT_DIR)\n",
    "print(\"SAVE_DIR:\", SAVE_DIR)\n",
    "\n",
    "# 4) Asegurar que 'src/' está en el path\n",
    "if str(SRC_DIR) not in sys.path:\n",
    "    sys.path.append(str(SRC_DIR))\n",
    "\n",
    "# 5) Verificaciones rápidas de artifacts\n",
    "assert (BASE_ARTI / \"dataset\").exists(), f\"Falta dataset en {BASE_ARTI/'dataset'}\"\n",
    "assert (BASE_ARTI / \"tokenizer\").exists(), f\"Falta tokenizer en {BASE_ARTI/'tokenizer'}\"\n",
    "print(\"Artifacts OK:\", BASE_ARTI)\n",
    "\n",
    "# 6) (Opcional) refrescar punteros \"latest\" a este RUN_ID\n",
    "try:\n",
    "    for link, target in [(LATEST_OUT, OUT_DIR), (LATEST_SAVE, SAVE_DIR)]:\n",
    "        if link.exists() or link.is_symlink():\n",
    "            link.unlink()\n",
    "        link.symlink_to(target, target_is_directory=True)\n",
    "    print(\"Punteros 'latest' actualizados.\")\n",
    "except Exception as e:\n",
    "    print(\"No se pudieron crear symlinks 'latest' (no crítico):\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76013a4ff1edfeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Local) Repo ya presente: no clonamos ni hacemos pull aquí.\n",
    "# Usamos DEST definido en la celda Bootstrap.\n",
    "from pathlib import Path\n",
    "\n",
    "assert 'DEST' in globals(), \"Asegúrate de ejecutar primero la celda Bootstrap que define DEST.\"\n",
    "assert (DEST / \"src\").exists(), f\"No se encontró src/ en {DEST}. Revisa tu ruta de trabajo o el montaje del volumen.\"\n",
    "\n",
    "print(\"Repo listo en:\", DEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a96f5aa",
   "metadata": {},
   "source": [
    "# === Visualización: helpers + callback en vivo === (Métricas)\n",
    "Define un callback que escucha los logs del Trainer y dibuja loss y F1 de validación a medida que avanza. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f1fcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, math\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output, display\n",
    "from transformers import TrainerCallback\n",
    "\n",
    "plt.rcParams.update({\"figure.figsize\": (6,4), \"axes.grid\": True})\n",
    "\n",
    "class LivePlotCallback(TrainerCallback):\n",
    "    \"\"\"\n",
    "    Dibuja durante el entrenamiento:\n",
    "      - training_loss (de logs)\n",
    "      - eval_f1 por epoch (cuando haya evaluación)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.steps, self.train_loss = [], []\n",
    "        self.epochs, self.eval_f1 = [], []\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if not logs:\n",
    "            return\n",
    "        # training loss (cada logging_steps)\n",
    "        if \"loss\" in logs and \"step\" in logs:\n",
    "            self.steps.append(state.global_step)\n",
    "            self.train_loss.append(logs[\"loss\"])\n",
    "        # eval por epoch\n",
    "        if \"eval_f1\" in logs and \"epoch\" in logs:\n",
    "            self.epochs.append(int(logs[\"epoch\"]))\n",
    "            self.eval_f1.append(logs[\"eval_f1\"])\n",
    "\n",
    "        # refresco “en vivo” cada ~N logs\n",
    "        if len(self.steps) % 10 == 0 or \"eval_f1\" in logs:\n",
    "            clear_output(wait=True)\n",
    "            fig, axs = plt.subplots(1, 2, figsize=(12,4))\n",
    "            # Loss\n",
    "            axs[0].plot(self.steps, self.train_loss, marker=\".\")\n",
    "            axs[0].set_title(\"Training loss\")\n",
    "            axs[0].set_xlabel(\"global_step\")\n",
    "            axs[0].set_ylabel(\"loss\")\n",
    "            # Eval F1\n",
    "            if self.eval_f1:\n",
    "                axs[1].plot(self.epochs, self.eval_f1, marker=\"o\")\n",
    "            axs[1].set_title(\"Eval F1 por epoch\")\n",
    "            axs[1].set_xlabel(\"epoch\")\n",
    "            axs[1].set_ylabel(\"F1\")\n",
    "            plt.tight_layout()\n",
    "            display(fig)\n",
    "            plt.close(fig)\n",
    "\n",
    "live_cb = LivePlotCallback()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b8827a",
   "metadata": {},
   "source": [
    "# Preparación de artifacts locales (entorno Docker+ROCm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3091ac2d262d9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Evita cargar TensorFlow por accidente (no lo usamos aquí)\n",
    "assert \"tensorflow\" not in sys.modules, \"TensorFlow está importado; desactívalo.\"\n",
    "\n",
    "# Usamos DEST de la celda Bootstrap como raíz del repo\n",
    "assert 'DEST' in globals(), \"Ejecuta primero la celda Bootstrap (define DEST).\"\n",
    "REPO_ROOT = DEST\n",
    "\n",
    "# Ruta local donde ya están los artifacts descomprimidos en tu repo:\n",
    "BASE_ARTI = REPO_ROOT / \"src\" / \"artifacts\" / \"hf_distilroberta\"\n",
    "\n",
    "# Valida que existan dataset/ y tokenizer/\n",
    "assert (BASE_ARTI / \"dataset\").exists(), f\"Falta {BASE_ARTI/'dataset'}\"\n",
    "assert (BASE_ARTI / \"tokenizer\").exists(), f\"Falta {BASE_ARTI/'tokenizer'}\"\n",
    "\n",
    "print(\"Artifacts en:\", BASE_ARTI)\n",
    "print(\"Contenido:\", sorted(p.name for p in BASE_ARTI.iterdir()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8739ca5",
   "metadata": {},
   "source": [
    "## Verificación ligera del stack (sin instalaciones en el notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b93f6ff707a83e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib.metadata import version as _ver, PackageNotFoundError\n",
    "\n",
    "def v(pkg):\n",
    "    try:\n",
    "        return _ver(pkg)\n",
    "    except PackageNotFoundError:\n",
    "        return None\n",
    "\n",
    "print(\"Stack de librerías:\", {\n",
    "    \"transformers\": v(\"transformers\"),\n",
    "    \"datasets\": v(\"datasets\"),\n",
    "    \"accelerate\": v(\"accelerate\"),\n",
    "    \"huggingface_hub\": v(\"huggingface_hub\"),\n",
    "    \"tokenizers\": v(\"tokenizers\"),\n",
    "    \"evaluate\": v(\"evaluate\"),\n",
    "    \"peft\": v(\"peft\"),\n",
    "    \"scikit-learn\": v(\"scikit-learn\"),\n",
    "})\n",
    "print(\"OK. Continúa con la celda de entrenamiento.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12efe72b",
   "metadata": {},
   "source": [
    "# ENTRENAMIENTO DEL MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666bc2bae3b3090f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#*** Carga dataset tokenizado y fine-tuning supervisado de DistilRoBERTa (binario 0/1) ***#\n",
    "from pathlib import Path\n",
    "import json, sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import load_from_disk\n",
    "\n",
    "# Asegura que no quede una versión previa de transformers en memoria\n",
    "sys.modules.pop(\"transformers\", None)\n",
    "\n",
    "import transformers  # import base primero para fijar versión en sys.modules\n",
    "print(\"Transformers version:\", transformers.__version__)\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoConfig, AutoModelForSequenceClassification,\n",
    "    TrainingArguments, Trainer, DataCollatorWithPadding, set_seed\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Directorio de salida (volumen persistente montado por Docker)\n",
    "OUT_DIR = \"/checkpoints/run_distilroberta\"\n",
    "\n",
    "# Localiza los artifacts\n",
    "# Reutiliza BASE_ARTI definido en la celda anterior; si no, usa ruta del repo\n",
    "if \"BASE_ARTI\" in globals():\n",
    "    BASE_ARTI = Path(BASE_ARTI)\n",
    "else:\n",
    "    assert 'DEST' in globals(), \"Ejecuta la celda Bootstrap para definir DEST.\"\n",
    "    BASE_ARTI = DEST / \"src\" / \"artifacts\" / \"hf_distilroberta\"\n",
    "\n",
    "# Si hubo anidamiento tipo hf_distilroberta/hf_distilroberta, corrige\n",
    "if not (BASE_ARTI / \"dataset\").exists() and (BASE_ARTI / \"hf_distilroberta\").exists():\n",
    "    BASE_ARTI = BASE_ARTI / \"hf_distilroberta\"\n",
    "\n",
    "assert (BASE_ARTI / \"dataset\").exists() and (BASE_ARTI / \"tokenizer\").exists(), \\\n",
    "    f\"Faltan dataset/ o tokenizer/ en {BASE_ARTI}. Revisa la celda de preparación de artifacts.\"\n",
    "print(\"OK artifacts:\", BASE_ARTI)\n",
    "\n",
    "# Dispositivo y GPU info (ROCm)\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"GPU disponible:\", torch.cuda.is_available(), \"| HIP:\", getattr(torch.version, \"hip\", None))\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Device 0:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# --- PARCHE ROBUSTO V2 para carga desde disk con datasets==4.x ---\n",
    "# Idempotente y sin recursión. Evita fallos al reconstruir `features` de DatasetInfo.\n",
    "import datasets\n",
    "\n",
    "DI = datasets.info.DatasetInfo\n",
    "Feat = datasets.Features\n",
    "\n",
    "# 1) Parchea from_dict una sola vez: si las features del JSON fallan, las ignora (None)\n",
    "if not hasattr(DI, \"_orig_from_dict\"):\n",
    "    DI._orig_from_dict = DI.from_dict\n",
    "\n",
    "    @classmethod\n",
    "    def _safe_from_dict(cls, dataset_info_dict: dict):\n",
    "        try:\n",
    "            return cls._orig_from_dict(dataset_info_dict)\n",
    "        except Exception as e:\n",
    "            dd = dict(dataset_info_dict or {})\n",
    "            if \"features\" in dd:\n",
    "                dd[\"features\"] = None\n",
    "            obj = cls._orig_from_dict(dd)\n",
    "            print(\"[patch] DatasetInfo.from_dict: ignorando 'features' corruptas -> usando None.\", f\"({type(e).__name__})\")\n",
    "            return obj\n",
    "\n",
    "    DI.from_dict = _safe_from_dict\n",
    "\n",
    "# 2) Sustituye __post_init__ por una versión NO recursiva y segura (una sola vez)\n",
    "if not hasattr(DI, \"_post_init_patched\"):\n",
    "    def _safe_post_init(self):\n",
    "        try:\n",
    "            f = getattr(self, \"features\", None)\n",
    "            if f is not None and not isinstance(f, Feat):\n",
    "                try:\n",
    "                    self.features = Feat.from_dict(f)\n",
    "                except Exception:\n",
    "                    self.features = None\n",
    "        except Exception:\n",
    "            self.features = None\n",
    "        # No llamamos al __post_init__ original\n",
    "\n",
    "    DI.__post_init__ = _safe_post_init\n",
    "    DI._post_init_patched = True\n",
    "# --- FIN PARCHE ROBUSTO V2 ---\n",
    "\n",
    "# dataset/tokenizer\n",
    "ds  = load_from_disk(str(BASE_ARTI / \"dataset\"))\n",
    "\n",
    "## Comprobación de splits + fallback opcional\n",
    "print(\"Splits disponibles:\", list(ds.keys()))\n",
    "needed = {\"train\", \"validation\", \"test\"}\n",
    "avail = set(ds.keys())\n",
    "\n",
    "## Si por accidente el split se llama \"dev\", lo renombramos a \"validation\"\n",
    "if \"validation\" not in avail and \"dev\" in avail:\n",
    "    ds[\"validation\"] = ds[\"dev\"]\n",
    "    del ds[\"dev\"]\n",
    "    avail = set(ds.keys())\n",
    "    print(\"Renombrado 'dev' -> 'validation'\")\n",
    "\n",
    "## Si faltan splits, corta con mensaje claro\n",
    "missing = needed - avail\n",
    "assert not missing, f\"Faltan splits: {missing}. Revisa el paso de tokenización/guardado.\"\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(str(BASE_ARTI / \"tokenizer\"), use_fast=True)\n",
    "\n",
    "# métricas (sklearn, evita evaluate.load)\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = (logits[:, 1] > logits[:, 0]).astype(int)\n",
    "\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    pr  = precision_score(labels, preds, zero_division=0)\n",
    "    rec = recall_score(labels, preds, zero_division=0)\n",
    "    f1  = f1_score(labels, preds, zero_division=0)\n",
    "\n",
    "    return {\"accuracy\": acc, \"precision\": pr, \"recall\": rec, \"f1\": f1}\n",
    "\n",
    "# class weights (si existen)\n",
    "cw = None\n",
    "meta_path = BASE_ARTI / \"preprocess_meta.json\"\n",
    "if meta_path.exists():\n",
    "    meta = json.loads(meta_path.read_text())\n",
    "    if \"class_weights\" in meta and isinstance(meta[\"class_weights\"], dict):\n",
    "        # admite claves \"0\"/\"1\" o 0/1\n",
    "        cw_map = {int(k): float(v) for k, v in meta[\"class_weights\"].items()}\n",
    "        cw = np.array([cw_map.get(0, 1.0), cw_map.get(1, 1.0)], dtype=np.float32)\n",
    "        print(\"Class weights:\", cw.tolist())\n",
    "\n",
    "# Comprobación de la ruta\n",
    "import os\n",
    "print(\"HF_HOME =\", os.environ.get(\"HF_HOME\"))\n",
    "print(\"HUGGINGFACE_HUB_CACHE =\", os.environ.get(\"HUGGINGFACE_HUB_CACHE\"))\n",
    "print(\"TRANSFORMERS_CACHE =\", os.environ.get(\"TRANSFORMERS_CACHE\"))\n",
    "##\n",
    "\n",
    "config = AutoConfig.from_pretrained(\"distilroberta-base\", num_labels=2)\n",
    "model  = AutoModelForSequenceClassification.from_pretrained(\"distilroberta-base\", config=config)\n",
    "\n",
    "# Collator que ignora claves no usadas por el modelo y añade labels aparte\n",
    "class SafeCollator(DataCollatorWithPadding):\n",
    "    def __call__(self, features):\n",
    "        # recoge labels (acepta 'labels' o 'label')\n",
    "        labels = []\n",
    "        cleaned = []\n",
    "        for f in features:\n",
    "            if \"labels\" in f:\n",
    "                labels.append(f[\"labels\"])\n",
    "            elif \"label\" in f:\n",
    "                labels.append(f[\"label\"])\n",
    "            # solo claves esperadas por el modelo\n",
    "            nf = {}\n",
    "            for k in (\"input_ids\", \"attention_mask\", \"token_type_ids\"):\n",
    "                if k in f:\n",
    "                    nf[k] = f[k]\n",
    "            cleaned.append(nf)\n",
    "\n",
    "        batch = self.tokenizer.pad(cleaned, padding=True, return_tensors=\"pt\")\n",
    "        if labels:\n",
    "            batch[\"labels\"] = torch.tensor(labels, dtype=torch.long)\n",
    "        return batch\n",
    "\n",
    "collator = SafeCollator(tokenizer=tok, return_tensors=\"pt\")\n",
    "\n",
    "# Trainer con pérdida ponderada (si hay weights) y filtrado de inputs\n",
    "class WeightedTrainer(Trainer):\n",
    "    def __init__(self, class_weights=None, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.class_weights = (\n",
    "            torch.tensor(class_weights, dtype=torch.float32) if class_weights is not None else None\n",
    "        )\n",
    "\n",
    "    # En Transformers 4.56.x, Trainer pasa num_items_in_batch; lo aceptamos e ignoramos.\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        # Acepta 'labels' o 'label'\n",
    "        labels = inputs.pop(\"labels\", None)\n",
    "        if labels is None and \"label\" in inputs:\n",
    "            labels = inputs.pop(\"label\")\n",
    "        if labels is None:\n",
    "            raise ValueError(\"Missing 'labels' in inputs\")\n",
    "\n",
    "        # Filtra claves inesperadas (evita pasar id/context_id al modelo)\n",
    "        allowed = {\"input_ids\", \"attention_mask\", \"token_type_ids\"}\n",
    "        model_inputs = {k: v for k, v in inputs.items() if k in allowed}\n",
    "\n",
    "        outputs = model(**model_inputs)\n",
    "        logits = outputs.logits  # [B, 2]\n",
    "\n",
    "        # CrossEntropy con o sin pesos\n",
    "        if self.class_weights is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss(weight=self.class_weights.to(logits.device))\n",
    "        else:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "\n",
    "        loss = loss_fct(logits.view(-1, 2), labels.view(-1).long())\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "# --- TrainingArguments (compatible 4.x) ---\n",
    "from inspect import signature\n",
    "\n",
    "TA = TrainingArguments\n",
    "ta_params = set(signature(TA).parameters.keys())\n",
    "\n",
    "# Compat: algunas versiones usan 'eval_strategy' en vez de 'evaluation_strategy'\n",
    "eval_key = \"evaluation_strategy\" if \"evaluation_strategy\" in ta_params else (\n",
    "    \"eval_strategy\" if \"eval_strategy\" in ta_params else None\n",
    ")\n",
    "\n",
    "# 'report_to' en versiones recientes debe ser lista (no string)\n",
    "report_to_val = []  # equivalente a \"none\"\n",
    "\n",
    "# Mezcla de precisión óptima en ROCm (usa bf16 si está soportado, si no fp16)\n",
    "use_bf16 = torch.cuda.is_available() and torch.cuda.is_bf16_supported()\n",
    "use_fp16 = torch.cuda.is_available() and not use_bf16\n",
    "\n",
    "# Opcional: algo de ahorro de VRAM con gradient checkpointing\n",
    "# (si notas el entrenamiento muy justo de VRAM, ponlo a True)\n",
    "gradient_checkpointing = False\n",
    "\n",
    "# Algo de rendimiento en matmul (no afecta a la reproducibilidad exacta)\n",
    "try:\n",
    "    torch.set_float32_matmul_precision(\"high\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "\n",
    "ta_kwargs = dict(\n",
    "    output_dir=OUT_DIR,\n",
    "    # Logging/eval/guardar por época: suficiente para tu workflow y ligero\n",
    "    save_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=50,\n",
    "\n",
    "    # Núcleo de entrenamiento\n",
    "    per_device_train_batch_size=16,   # efectivo 32 con grad_accum, ver abajo\n",
    "    per_device_eval_batch_size=32,    # eval cabe bien con 16 GB VRAM\n",
    "    gradient_accumulation_steps=2,    # efectivo 32 -> estable y rápido\n",
    "    num_train_epochs=3,               # sube a 4 si quieres exprimir un poco más\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    max_grad_norm=1.0,\n",
    "\n",
    "    # Precisión mixta en ROCm\n",
    "    bf16=use_bf16,\n",
    "    fp16=use_fp16,\n",
    "\n",
    "    # Optimizador/planificador robustos\n",
    "    optim=\"adamw_torch\",\n",
    "    lr_scheduler_type=\"cosine\",       # suave; alternativa: \"linear\"\n",
    "\n",
    "    # Rendimiento DataLoader\n",
    "    dataloader_num_workers=4,         # súbelo a 6–8 si el disco da de sí\n",
    "    dataloader_pin_memory=True,\n",
    "\n",
    "    # Infra de Trainer\n",
    "    report_to=[],                     # sin wandb/tensorboard\n",
    "    remove_unused_columns=False,      # mantenemos id/context_id\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    seed=42,\n",
    "\n",
    "    # Compilación desactivada por defecto (a veces inestable en ROCm)\n",
    "    torch_compile=False,\n",
    "\n",
    "    #Si se queda corto/largo de VRAM (OOM/sobra)\n",
    "    #OOM: baja per_device_train_batch_size a 12 o 8; o pon gradient_checkpointing=True (más lento pero ahorra VRAM).\n",
    "    #Sobra VRAM y quieres apretar: sube per_device_train_batch_size a 20–24 y baja gradient_accumulation_steps a 1 (o mantén 2 para más estabilidad).\n",
    ")\n",
    "\n",
    "# Activa gradient checkpointing si lo pediste arriba\n",
    "if gradient_checkpointing:\n",
    "    model.gradient_checkpointing_enable()\n",
    "\n",
    "# Si existe clave de evaluación, la añadimos con \"epoch\"\n",
    "if eval_key is not None:\n",
    "    ta_kwargs[eval_key] = \"epoch\"\n",
    "else:\n",
    "    print(\"[warn] TrainingArguments sin evaluation_strategy/eval_strategy; usando configuración por defecto.\")\n",
    "\n",
    "args = TA(**ta_kwargs)\n",
    "\n",
    "trainer = WeightedTrainer(\n",
    "    class_weights=cw,\n",
    "    model=model, args=args,\n",
    "    train_dataset=ds[\"train\"],\n",
    "    eval_dataset=ds[\"validation\"],\n",
    "    tokenizer=tok,\n",
    "    data_collator=collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[live_cb],\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "print(\"\\n== Eval (validation) justo tras entrenamiento ==\")\n",
    "metrics_val = trainer.evaluate(eval_dataset=ds[\"validation\"])\n",
    "for k, v in metrics_val.items():\n",
    "    print(f\"{k}: {v:.4f}\" if isinstance(v, (int, float)) else f\"{k}: {v}\")\n",
    "\n",
    "\n",
    "SAVE_DIR = Path(\"/checkpoints/model_distilroberta_ft\")\n",
    "trainer.save_model(str(SAVE_DIR))\n",
    "tok.save_pretrained(str(SAVE_DIR))\n",
    "print(\"Modelo guardado en:\", SAVE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31141894",
   "metadata": {},
   "source": [
    "# === Post-entrenamiento: curvas desde logs ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07811c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curvas de entrenamiento SIN widgets (robusto en VS Code/ROCm)\n",
    "# - Funciona aunque hayas reiniciado el kernel (lee trainer_state.json)\n",
    "# - Guarda PNG y CSV con las métricas\n",
    "\n",
    "import os, json, math\n",
    "from pathlib import Path\n",
    "\n",
    "# 0) Backend no interactivo *antes* de importar pyplot\n",
    "import matplotlib as mpl\n",
    "mpl.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display\n",
    "import csv\n",
    "\n",
    "# 1) Localiza OUT_DIR y trainer_state.json\n",
    "assert 'OUT_DIR' in globals(), \"OUT_DIR no está definido (ejecuta Bootstrap/entrenamiento).\"\n",
    "OUT_DIR = Path(OUT_DIR)\n",
    "ts_path = OUT_DIR / \"trainer_state.json\"\n",
    "\n",
    "# 2) Cargar log_history (memoria o disco)\n",
    "log_history = []\n",
    "if 'trainer' in globals() and hasattr(trainer, 'state') and trainer.state.log_history:\n",
    "    log_history = trainer.state.log_history\n",
    "\n",
    "if (not log_history) and ts_path.exists():\n",
    "    with ts_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        ts = json.load(f)\n",
    "    log_history = ts.get(\"log_history\", [])\n",
    "\n",
    "print(f\"log_history registros: {len(log_history)}\")\n",
    "if not log_history:\n",
    "    print(f\"⚠️ No hay logs. ¿Se ejecutó entrenamiento? Revisar {ts_path}\")\n",
    "\n",
    "# 3) Extraer series\n",
    "steps, tr_loss = [], []\n",
    "epx, eval_f1, eval_prec, eval_rec, eval_acc = [], [], [], [], []\n",
    "lrs, lr_steps = [], []\n",
    "\n",
    "for e in log_history:\n",
    "    # loss por step (solo si se configuró logging por pasos)\n",
    "    if \"loss\" in e and \"step\" in e:\n",
    "        steps.append(e[\"step\"])\n",
    "        tr_loss.append(e[\"loss\"])\n",
    "    # lr scheduler (si se logueó)\n",
    "    if \"learning_rate\" in e and \"step\" in e:\n",
    "        lr_steps.append(e[\"step\"])\n",
    "        lrs.append(e[\"learning_rate\"])\n",
    "    # métricas de validación por epoch\n",
    "    if \"eval_f1\" in e:\n",
    "        ep = e.get(\"epoch\")\n",
    "        if ep is None:\n",
    "            ep = (epx[-1] + 1) if epx else 1\n",
    "        ep = int(ep) if isinstance(ep, (int, float)) and not math.isnan(ep) else ep\n",
    "        epx.append(ep)\n",
    "        eval_f1.append(e[\"eval_f1\"])\n",
    "        eval_prec.append(e.get(\"eval_precision\", float(\"nan\")))\n",
    "        eval_rec.append(e.get(\"eval_recall\", float(\"nan\")))\n",
    "        eval_acc.append(e.get(\"eval_accuracy\", float(\"nan\")))\n",
    "\n",
    "# 4) Dibujar y guardar PNG\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# (A) Training loss\n",
    "axs[0].plot(steps, tr_loss, marker=\".\", linestyle=\"-\")\n",
    "axs[0].set_title(\"Training loss (logs)\")\n",
    "axs[0].set_xlabel(\"global_step\"); axs[0].set_ylabel(\"loss\")\n",
    "if not steps:\n",
    "    axs[0].text(0.5, 0.5, \"Sin logs por pasos.\\nUsa logging_strategy='steps' y logging_steps.\",\n",
    "                ha=\"center\", va=\"center\", transform=axs[0].transAxes)\n",
    "\n",
    "# (B) Métricas de validación por epoch\n",
    "axs[1].plot(epx, eval_f1,   marker=\"o\", label=\"F1\")\n",
    "axs[1].plot(epx, eval_prec, marker=\"o\", label=\"Precision\")\n",
    "axs[1].plot(epx, eval_rec,  marker=\"o\", label=\"Recall\")\n",
    "axs[1].plot(epx, eval_acc,  marker=\"o\", label=\"Accuracy\")\n",
    "axs[1].set_title(\"Métricas de validación por época\")\n",
    "axs[1].set_xlabel(\"epoch\"); axs[1].legend()\n",
    "if not epx:\n",
    "    axs[1].text(0.5, 0.5, \"Sin métricas de validación.\\n¿evaluation_strategy='epoch'?\",\n",
    "                ha=\"center\", va=\"center\", transform=axs[1].transAxes)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# 5) Salvar figuras/CSV en el repo\n",
    "FIG_DIR = Path.cwd() / \"figs\"\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "png_path = FIG_DIR / \"training_curves.png\"\n",
    "plt.savefig(png_path, dpi=150, bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "\n",
    "# CSV con métricas por epoch (si existen)\n",
    "csv_path = FIG_DIR / \"validation_metrics_by_epoch.csv\"\n",
    "if epx:\n",
    "    with csv_path.open(\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow([\"epoch\", \"f1\", \"precision\", \"recall\", \"accuracy\"])\n",
    "        for i in range(len(epx)):\n",
    "            w.writerow([epx[i], eval_f1[i], eval_prec[i], eval_rec[i], eval_acc[i]])\n",
    "\n",
    "print(\"Figura guardada en:\", png_path)\n",
    "if epx:\n",
    "    print(\"CSV guardado en:\", csv_path)\n",
    "\n",
    "display(Image(filename=str(png_path)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08bb35a",
   "metadata": {},
   "source": [
    "## Calibración autónoma desde disco (sin reentrenar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abed048bb36f0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json, numpy as np, torch\n",
    "from datasets import load_from_disk\n",
    "from transformers import (AutoTokenizer, AutoConfig, AutoModelForSequenceClassification,\n",
    "                          TrainingArguments, Trainer, DataCollatorWithPadding)\n",
    "\n",
    "# RUTAS (locales)\n",
    "if \"BASE_ARTI\" in globals():\n",
    "    BASE_ARTI = Path(BASE_ARTI)\n",
    "else:\n",
    "    assert 'DEST' in globals(), \"Ejecuta la celda Bootstrap para definir DEST.\"\n",
    "    BASE_ARTI = DEST / \"src\" / \"artifacts\" / \"hf_distilroberta\"\n",
    "\n",
    "SAVE_DIR = Path(\"/checkpoints/model_distilroberta_ft\")\n",
    "OUT_TMP  = (DEST / \"tmp_calib\"); OUT_TMP.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 1) Dataset y tokenizer\n",
    "ds  = load_from_disk(str(BASE_ARTI / \"dataset\"))\n",
    "tok = AutoTokenizer.from_pretrained(str(BASE_ARTI / \"tokenizer\"), use_fast=True)\n",
    "\n",
    "# 2) Modelo (final)\n",
    "config = AutoConfig.from_pretrained(str(SAVE_DIR))\n",
    "model  = AutoModelForSequenceClassification.from_pretrained(str(SAVE_DIR), config=config)\n",
    "\n",
    "# 3) Trainer “ligero” solo para predict\n",
    "args = TrainingArguments(\n",
    "    output_dir=str(OUT_TMP),\n",
    "    per_device_eval_batch_size=128,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    dataloader_num_workers=2,\n",
    "    report_to=[]\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model, args=args, processing_class=tok,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tok, return_tensors=\"pt\")\n",
    ")\n",
    "\n",
    "# --- Calibración rápida (un único predict) ---\n",
    "def _prepare_pred_dataset(split):\n",
    "    d = ds[split]\n",
    "    cols = d.column_names\n",
    "    label_col = \"labels\" if \"labels\" in cols else (\"label\" if \"label\" in cols else None)\n",
    "    assert label_col is not None, f\"Split {split} sin columna de label.\"\n",
    "    keep = [\"input_ids\", \"attention_mask\", label_col] + ([\"token_type_ids\"] if \"token_type_ids\" in cols else [])\n",
    "    ids = d[\"id\"] if \"id\" in cols else list(range(len(d)))\n",
    "    ctx = d[\"context_id\"] if \"context_id\" in cols else [0] * len(d)\n",
    "    pred_ds = d.remove_columns([c for c in cols if c not in keep])\n",
    "    labels = np.array(d[label_col])\n",
    "    return pred_ds, labels, np.array(ids), np.array(ctx)\n",
    "\n",
    "def logits_labels_ids(split):\n",
    "    pred_ds, labels, ids, ctx = _prepare_pred_dataset(split)\n",
    "    logits = trainer.predict(pred_ds).predictions  # [N, 2]\n",
    "    return logits, labels, ids, ctx\n",
    "\n",
    "def softmax_np(x):\n",
    "    x = x - x.max(axis=-1, keepdims=True)\n",
    "    ex = np.exp(x)\n",
    "    return ex / ex.sum(axis=-1, keepdims=True)\n",
    "\n",
    "logits_val, labels_val, ids_val, ctx_val = logits_labels_ids(\"validation\")\n",
    "p1_val = softmax_np(logits_val)[:, 1]\n",
    "\n",
    "# Pooling máximo por comentario (id, context_id)\n",
    "keys = np.core.defchararray.add(ids_val.astype(str), \"::\" + ctx_val.astype(str))\n",
    "order = np.argsort(keys)\n",
    "keys_s, p1_s, y_s = keys[order], p1_val[order], labels_val[order]\n",
    "grp_st = np.r_[0, 1 + np.flatnonzero(keys_s[1:] != keys_s[:-1])]\n",
    "pooled_p1 = np.maximum.reduceat(p1_s, grp_st)\n",
    "pooled_y  = y_s[grp_st].astype(int)\n",
    "\n",
    "TARGET_PREC = 0.90\n",
    "ord_desc = np.argsort(-pooled_p1)\n",
    "scores = pooled_p1[ord_desc]\n",
    "y_true = pooled_y[ord_desc]\n",
    "tp = np.cumsum(y_true); fp = np.cumsum(1 - y_true); fn_tot = y_true.sum()\n",
    "prec = tp / np.maximum(tp + fp, 1e-9)\n",
    "rec  = tp / np.maximum(fn_tot, 1e-9)\n",
    "mask = prec >= TARGET_PREC\n",
    "best_idx = int(np.argmax(rec * mask)) if np.any(mask) else int(np.argmax(prec))\n",
    "best_thr, best_prec, best_rec = float(scores[best_idx]), float(prec[best_idx]), float(rec[best_idx])\n",
    "\n",
    "(SAVE_DIR / \"threshold.json\").write_text(json.dumps({\n",
    "    \"threshold\": best_thr,\n",
    "    \"target_precision\": TARGET_PREC,\n",
    "    \"precision_at_threshold\": best_prec,\n",
    "    \"recall_at_threshold\": best_rec\n",
    "}, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "print(f\"[calibración] threshold={best_thr:.4f} | precision={best_prec:.4f} | recall={best_rec:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd154bbe",
   "metadata": {},
   "source": [
    "# === Visualización de calibración (usar variables ya calculadas) ===\n",
    "Muestra la curva PR y la distribución de puntuaciones por clase (válido para la memoria del TFG). Además guarda `val_pooled_scores.npy` y `val_pooled_labels.npy` en SAVE_DIR por si se necesita \"replotear\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb4e133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardado para reutilizar en otra sesión\n",
    "np.save(Path(SAVE_DIR, \"val_pooled_scores.npy\"), scores)     # prob. clase 1 por comentario\n",
    "np.save(Path(SAVE_DIR, \"val_pooled_labels.npy\"), y_true.astype(int))\n",
    "\n",
    "# Curva Prec-Recall (ordenando por score desc, ya lo tenemos)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(rec, prec)\n",
    "plt.scatter([best_rec], [best_prec], marker=\"o\", label=f\"thr={best_thr:.3f}\")\n",
    "plt.title(\"Precision-Recall (validación, pooling=max)\")\n",
    "plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.legend(); plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Histograma de puntuaciones\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(scores[y_true==0], bins=30, alpha=0.6, label=\"negativos\")\n",
    "plt.hist(scores[y_true==1], bins=30, alpha=0.6, label=\"positivos\")\n",
    "plt.axvline(best_thr, ls=\"--\", label=f\"threshold={best_thr:.3f}\")\n",
    "plt.title(\"Distribución de puntuaciones (pooled p1)\")\n",
    "plt.xlabel(\"p1 (pooled)\"); plt.ylabel(\"count\"); plt.legend(); plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f4f63d36449468",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluación final en TEST (pooling por comentario)\n",
    "import json, numpy as np, torch\n",
    "from pathlib import Path\n",
    "from datasets import load_from_disk\n",
    "from transformers import (AutoTokenizer, AutoConfig, AutoModelForSequenceClassification,\n",
    "                          TrainingArguments, Trainer, DataCollatorWithPadding)\n",
    "\n",
    "# Rutas\n",
    "if \"BASE_ARTI\" in globals():\n",
    "    BASE_ARTI = Path(BASE_ARTI)\n",
    "else:\n",
    "    assert 'DEST' in globals(), \"Ejecuta la celda Bootstrap para definir DEST.\"\n",
    "    BASE_ARTI = DEST / \"src\" / \"artifacts\" / \"hf_distilroberta\"\n",
    "\n",
    "SAVE_DIR = Path(\"/checkpoints/model_distilroberta_ft\")\n",
    "thr = float(json.loads((SAVE_DIR / \"threshold.json\").read_text())[\"threshold\"])\n",
    "\n",
    "# Carga\n",
    "ds  = load_from_disk(str(BASE_ARTI / \"dataset\"))\n",
    "tok = AutoTokenizer.from_pretrained(str(BASE_ARTI / \"tokenizer\"), use_fast=True)\n",
    "config = AutoConfig.from_pretrained(str(SAVE_DIR))\n",
    "model  = AutoModelForSequenceClassification.from_pretrained(str(SAVE_DIR), config=config)\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=str(DEST / \"tmp_eval\"),\n",
    "    per_device_eval_batch_size=128,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    dataloader_num_workers=2,\n",
    "    report_to=[]\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model, args=args, processing_class=tok,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tok, return_tensors=\"pt\")\n",
    ")\n",
    "\n",
    "def _prep(split):\n",
    "    d = ds[split]; cols = d.column_names\n",
    "    label_col = \"labels\" if \"labels\" in cols else \"label\"\n",
    "    keep = [\"input_ids\",\"attention_mask\",label_col] + ([\"token_type_ids\"] if \"token_type_ids\" in cols else [])\n",
    "    ids = d[\"id\"] if \"id\" in cols else list(range(len(d)))\n",
    "    ctx = d[\"context_id\"] if \"context_id\" in cols else [0]*len(d)\n",
    "    pred_ds = d.remove_columns([c for c in cols if c not in keep])\n",
    "    labels = np.array(d[label_col])\n",
    "    return pred_ds, labels, np.array(ids), np.array(ctx)\n",
    "\n",
    "def _softmax(x): x=x-x.max(axis=-1,keepdims=True); ex=np.exp(x); return ex/ex.sum(axis=-1,keepdims=True)\n",
    "\n",
    "def _pooled(split):\n",
    "    pred_ds, labels, ids, ctx = _prep(split)\n",
    "    logits = trainer.predict(pred_ds).predictions\n",
    "    p1 = _softmax(logits)[:,1]\n",
    "    keys = np.core.defchararray.add(ids.astype(str),\"::\"+ctx.astype(str))\n",
    "    order = np.argsort(keys); keys_s,p1_s,y_s = keys[order],p1[order],labels[order]\n",
    "    grp = np.r_[0,1+np.flatnonzero(keys_s[1:]!=keys_s[:-1])]\n",
    "    pooled_p1 = np.maximum.reduceat(p1_s, grp)\n",
    "    pooled_y  = y_s[grp].astype(int)\n",
    "    return pooled_p1, pooled_y\n",
    "\n",
    "def _metrics(split, thr):\n",
    "    scores, y_true = _pooled(split)\n",
    "    pred = (scores >= thr).astype(int)\n",
    "    tp = int(((pred==1)&(y_true==1)).sum())\n",
    "    fp = int(((pred==1)&(y_true==0)).sum())\n",
    "    fn = int(((pred==0)&(y_true==1)).sum())\n",
    "    tn = int(((pred==0)&(y_true==0)).sum())\n",
    "    prec = tp / max(tp+fp, 1e-9)\n",
    "    rec  = tp / max(tp+fn, 1e-9)\n",
    "    f1   = 2*prec*rec / max(prec+rec, 1e-9)\n",
    "    acc  = (tp+tn) / max(tp+tn+fp+fn, 1e-9)\n",
    "    return dict(precision=prec, recall=rec, f1=f1, accuracy=acc,\n",
    "                counts=dict(tp=tp, fp=fp, fn=fn, tn=tn))\n",
    "\n",
    "val_metrics  = _metrics(\"validation\", thr)\n",
    "test_metrics = _metrics(\"test\", thr)\n",
    "\n",
    "(SAVE_DIR / \"eval_comment_level.json\").write_text(\n",
    "    json.dumps({\"validation\": val_metrics, \"test\": test_metrics}, indent=2), encoding=\"utf-8\"\n",
    ")\n",
    "(SAVE_DIR / \"inference_meta.json\").write_text(\n",
    "    json.dumps({\"pooling\":\"max\", \"threshold\": float(thr)}, indent=2), encoding=\"utf-8\"\n",
    ")\n",
    "\n",
    "print(\"VAL:\", val_metrics)\n",
    "print(\"TEST:\", test_metrics)\n",
    "print(\"Guardado en:\", SAVE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34ba1b7",
   "metadata": {},
   "source": [
    "# === Matriz de confusión (valid/test) ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2749eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion(cm, title):\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.imshow(cm, interpolation=\"nearest\")\n",
    "    plt.title(title)\n",
    "    plt.xticks([0,1], [\"Pred 0\",\"Pred 1\"])\n",
    "    plt.yticks([0,1], [\"True 0\",\"True 1\"])\n",
    "    for (i,j), v in np.ndenumerate(cm):\n",
    "        plt.text(j, i, str(v), ha=\"center\", va=\"center\", color=\"white\" if v>cm.max()/2 else \"black\")\n",
    "    plt.colorbar(); plt.tight_layout(); plt.show()\n",
    "\n",
    "cm_val = np.array([[val_metrics[\"counts\"][\"tn\"], val_metrics[\"counts\"][\"fp\"]],\n",
    "                   [val_metrics[\"counts\"][\"fn\"], val_metrics[\"counts\"][\"tp\"]]])\n",
    "cm_tst = np.array([[test_metrics[\"counts\"][\"tn\"], test_metrics[\"counts\"][\"fp\"]],\n",
    "                   [test_metrics[\"counts\"][\"fn\"], test_metrics[\"counts\"][\"tp\"]]])\n",
    "\n",
    "plot_confusion(cm_val, \"Confusion Matrix (VALID)\")\n",
    "plot_confusion(cm_tst, \"Confusion Matrix (TEST)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef0f33d0ca143b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## \"Pack\" final listo para reutilizar/re-entrenar (en el propio repo)\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "DEPLOY_DIR = DEST / \"deploy_distilroberta\"\n",
    "if DEPLOY_DIR.exists():\n",
    "    shutil.rmtree(DEPLOY_DIR)\n",
    "shutil.copytree(SAVE_DIR, DEPLOY_DIR)\n",
    "print(\"Pack listo en:\", DEPLOY_DIR)\n",
    "print(\"Contenidos:\", [p.name for p in DEPLOY_DIR.iterdir()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
