{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14e819c4",
   "metadata": {},
   "source": [
    "# COMPROBACIONES PREVIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5ac278",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, torch, subprocess, json\n",
    "print(\"PY:\", sys.executable)\n",
    "print(\"CWD:\", os.getcwd())\n",
    "print(\"torch:\", torch.__version__, \" HIP:\", getattr(torch.version, \"hip\", None), \" CUDA:\", getattr(torch.version, \"cuda\", None))\n",
    "print(\"GPU? \", torch.cuda.is_available())\n",
    "\n",
    "# ¿Existen los dispositivos GPU?\n",
    "print(\"\\n/dev/kfd exists?\", os.path.exists(\"/dev/kfd\"))\n",
    "print(\"/dev/dri/renderD128 exists?\", os.path.exists(\"/dev/dri/renderD128\"))\n",
    "\n",
    "# ¿Estoy en el venv correcto?\n",
    "print(\"\\nsite-packages:\", next(p for p in sys.path if p.endswith(\"site-packages\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7300d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os, transformers\n",
    "print(\"GPU?\", torch.cuda.is_available(), getattr(torch.version, \"hip\", None))\n",
    "if torch.cuda.is_available(): print(torch.cuda.get_device_name(0))\n",
    "print(\"HF_HOME:\", os.environ.get(\"HF_HOME\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc86038d54c2a122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap\n",
    "# === Preparación del entorno para la ejecución de todas las celdas (entorno local Docker+ROCm) ===\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# 1) Variables de entorno (en Docker ya vienen saneadas, aquí solo las fijamos por si faltan)\n",
    "os.environ.setdefault(\"HF_HOME\", \"/root/.cache/huggingface\")   # cache local persistida por volumen\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"                 # evita deadlocks\n",
    "os.environ[\"HF_HUB_DISABLE_TELEMETRY\"] = \"1\"\n",
    "Path(os.environ[\"HF_HOME\"]).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 2) Localización del repo (sin Drive, sin git clone). Buscamos la raíz que contenga src/ y requirements.txt\n",
    "def _find_repo_root(start: Path) -> Path:\n",
    "    for p in [start, *start.parents]:\n",
    "        if (p / \"src\").exists() and (p / \"requirements.txt\").exists():\n",
    "            return p\n",
    "    return start  # fallback: cwd\n",
    "\n",
    "REPO_ROOT = _find_repo_root(Path.cwd())\n",
    "DEST = REPO_ROOT  # mantenemos el nombre usado en el resto del cuaderno\n",
    "\n",
    "# 3) Añadir src/ al PYTHONPATH\n",
    "sys.path.append(str(DEST / \"src\"))\n",
    "\n",
    "print(\"Entorno listo.\")\n",
    "print(\"HF_HOME:\", os.environ[\"HF_HOME\"])\n",
    "print(\"Repo root:\", DEST)\n",
    "print(\"SRC en sys.path:\", str(DEST / \"src\") in sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76013a4ff1edfeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Local) Repo ya presente: no clonamos ni hacemos pull aquí.\n",
    "# Usamos DEST definido en la celda Bootstrap.\n",
    "from pathlib import Path\n",
    "\n",
    "assert 'DEST' in globals(), \"Asegúrate de ejecutar primero la celda Bootstrap que define DEST.\"\n",
    "assert (DEST / \"src\").exists(), f\"No se encontró src/ en {DEST}. Revisa tu ruta de trabajo o el montaje del volumen.\"\n",
    "\n",
    "print(\"Repo listo en:\", DEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5e9ecbe8b2535b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4) Añadir tu src al PYTHONPATH y verificar estructura ---\n",
    "import sys\n",
    "sys.path.append(str(DEST / \"src\"))\n",
    "\n",
    "!ls -la /content/repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3091ac2d262d9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparación de artifacts locales (entorno Docker+ROCm)\n",
    "import os, sys, zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "# Evita cargar TensorFlow por accidente (no lo usamos aquí)\n",
    "assert \"tensorflow\" not in sys.modules, \"TensorFlow está importado; desactívalo.\"\n",
    "\n",
    "# Usamos DEST de la celda Bootstrap como raíz del repo\n",
    "assert 'DEST' in globals(), \"Ejecuta primero la celda Bootstrap (define DEST).\"\n",
    "REPO_ROOT = DEST\n",
    "\n",
    "# Carpeta donde dejaremos/leeremos los artifacts\n",
    "ART_DIR = Path(\"/workspace/BERTolto/artifacts\")\n",
    "ART_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Intentamos localizar el ZIP existente (ajusta si lo guardaste en otro sitio)\n",
    "ZIP_CANDIDATES = [\n",
    "    REPO_ROOT / \"data\" / \"hf_distilroberta.zip\",\n",
    "    REPO_ROOT / \"artifacts\" / \"hf_distilroberta.zip\",\n",
    "    Path.home() / \"BERTolto\" / \"data\" / \"hf_distilroberta.zip\",\n",
    "]\n",
    "\n",
    "zip_path = next((p for p in ZIP_CANDIDATES if p.exists()), None)\n",
    "\n",
    "# Extrae solo si no está ya la carpeta descomprimida\n",
    "BASE_ARTI = ART_DIR / \"hf_distilroberta\"\n",
    "if zip_path and not BASE_ARTI.exists():\n",
    "    print(f\"Descomprimiendo: {zip_path} -> {ART_DIR}\")\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zf:\n",
    "        zf.extractall(ART_DIR)\n",
    "\n",
    "# Valida que exista la carpeta final\n",
    "assert BASE_ARTI.exists(), (\n",
    "    f\"No se encontró {BASE_ARTI}. Coloca 'hf_distilroberta.zip' en \"\n",
    "    f\"'{REPO_ROOT}/data' o '{REPO_ROOT}/artifacts', o extrae manualmente la carpeta aquí.\"\n",
    ")\n",
    "\n",
    "print(\"Artifacts en:\", BASE_ARTI)\n",
    "print(\"Contenido:\", [p.name for p in BASE_ARTI.iterdir()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b93f6ff707a83e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificación ligera del stack (sin instalaciones en el notebook)\n",
    "from importlib.metadata import version as _ver, PackageNotFoundError\n",
    "\n",
    "def v(pkg):\n",
    "    try:\n",
    "        return _ver(pkg)\n",
    "    except PackageNotFoundError:\n",
    "        return None\n",
    "\n",
    "print(\"Stack de librerías:\", {\n",
    "    \"transformers\": v(\"transformers\"),\n",
    "    \"datasets\": v(\"datasets\"),\n",
    "    \"accelerate\": v(\"accelerate\"),\n",
    "    \"huggingface_hub\": v(\"huggingface_hub\"),\n",
    "    \"tokenizers\": v(\"tokenizers\"),\n",
    "    \"evaluate\": v(\"evaluate\"),\n",
    "    \"peft\": v(\"peft\"),\n",
    "    \"scikit-learn\": v(\"scikit-learn\"),\n",
    "})\n",
    "print(\"OK. Continúa con la celda de entrenamiento.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666bc2bae3b3090f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENTRENAMIENTO DEL MODELO\n",
    "\n",
    "#*** Carga dataset tokenizado y fine-tuning supervisado de DistilRoBERTa (binario 0/1) ***#\n",
    "from pathlib import Path\n",
    "import json, sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import load_from_disk\n",
    "\n",
    "# Asegura que no quede una versión previa de transformers en memoria\n",
    "sys.modules.pop(\"transformers\", None)\n",
    "\n",
    "import transformers  # import base primero para fijar versión en sys.modules\n",
    "print(\"Transformers version:\", transformers.__version__)\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoConfig, AutoModelForSequenceClassification,\n",
    "    TrainingArguments, Trainer, DataCollatorWithPadding, set_seed\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Directorio de salida (volumen persistente montado por Docker)\n",
    "OUT_DIR = \"/checkpoints/run_distilroberta\"\n",
    "\n",
    "# Localiza los artifacts\n",
    "# Si la celda de \"Preparación de artifacts\" ya definió BASE_ARTI, la reutilizamos.\n",
    "# Si no, hacemos fallback a la ruta estándar dentro del repo.\n",
    "if \"BASE_ARTI\" in globals():\n",
    "    BASE_ARTI = Path(BASE_ARTI)\n",
    "else:\n",
    "    BASE_ARTI = Path(\"/workspace/BERTolto/artifacts/hf_distilroberta\")\n",
    "\n",
    "# Si hubo anidamiento tipo hf_distilroberta/hf_distilroberta, corrige\n",
    "if not (BASE_ARTI / \"dataset\").exists() and (BASE_ARTI / \"hf_distilroberta\").exists():\n",
    "    BASE_ARTI = BASE_ARTI / \"hf_distilroberta\"\n",
    "\n",
    "assert (BASE_ARTI / \"dataset\").exists() and (BASE_ARTI / \"tokenizer\").exists(), \\\n",
    "    f\"Faltan dataset/ o tokenizer/ en {BASE_ARTI}. Revisa la celda de preparación de artifacts.\"\n",
    "print(\"OK artifacts:\", BASE_ARTI)\n",
    "\n",
    "# Dispositivo y GPU info (ROCm)\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"GPU disponible:\", torch.cuda.is_available(),\n",
    "      \"| HIP:\", getattr(torch.version, \"hip\", None))\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Device 0:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# --- PARCHE ROBUSTO V2 para carga desde disk con datasets==4.x ---\n",
    "# Idempotente y sin recursión. Evita fallos al reconstruir `features` de DatasetInfo.\n",
    "import datasets\n",
    "\n",
    "DI = datasets.info.DatasetInfo\n",
    "Feat = datasets.Features\n",
    "\n",
    "# 1) Parchea from_dict una sola vez: si las features del JSON fallan, las ignora (None)\n",
    "if not hasattr(DI, \"_orig_from_dict\"):\n",
    "    DI._orig_from_dict = DI.from_dict\n",
    "\n",
    "    @classmethod\n",
    "    def _safe_from_dict(cls, dataset_info_dict: dict):\n",
    "        try:\n",
    "            return cls._orig_from_dict(dataset_info_dict)\n",
    "        except Exception as e:\n",
    "            dd = dict(dataset_info_dict or {})\n",
    "            if \"features\" in dd:\n",
    "                dd[\"features\"] = None\n",
    "            obj = cls._orig_from_dict(dd)\n",
    "            print(\"[patch] DatasetInfo.from_dict: ignorando 'features' corruptas -> usando None.\",\n",
    "                  f\"({type(e).__name__})\")\n",
    "            return obj\n",
    "\n",
    "    DI.from_dict = _safe_from_dict\n",
    "\n",
    "# 2) Sustituye __post_init__ por una versión NO recursiva y segura (una sola vez)\n",
    "if not hasattr(DI, \"_post_init_patched\"):\n",
    "    def _safe_post_init(self):\n",
    "        try:\n",
    "            f = getattr(self, \"features\", None)\n",
    "            if f is not None and not isinstance(f, Feat):\n",
    "                try:\n",
    "                    self.features = Feat.from_dict(f)\n",
    "                except Exception:\n",
    "                    self.features = None\n",
    "        except Exception:\n",
    "            self.features = None\n",
    "        # No llamamos al __post_init__ original\n",
    "\n",
    "    DI.__post_init__ = _safe_post_init\n",
    "    DI._post_init_patched = True\n",
    "# --- FIN PARCHE ROBUSTO V2 ---\n",
    "\n",
    "# dataset/tokenizer\n",
    "ds  = load_from_disk(str(BASE_ARTI / \"dataset\"))\n",
    "\n",
    "## Comprobación de splits + fallback opcional\n",
    "print(\"Splits disponibles:\", list(ds.keys()))\n",
    "needed = {\"train\", \"validation\", \"test\"}\n",
    "avail = set(ds.keys())\n",
    "\n",
    "## Si por accidente el split se llama \"dev\", lo renombramos a \"validation\"\n",
    "if \"validation\" not in avail and \"dev\" in avail:\n",
    "    ds[\"validation\"] = ds[\"dev\"]\n",
    "    del ds[\"dev\"]\n",
    "    avail = set(ds.keys())\n",
    "    print(\"Renombrado 'dev' -> 'validation'\")\n",
    "\n",
    "## Si faltan splits, corta con mensaje claro\n",
    "missing = needed - avail\n",
    "assert not missing, f\"Faltan splits: {missing}. Revisa el paso de tokenización/guardado.\"\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(str(BASE_ARTI / \"tokenizer\"), use_fast=True)\n",
    "\n",
    "# métricas (sklearn, evita evaluate.load)\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = (logits[:, 1] > logits[:, 0]).astype(int)\n",
    "\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    pr  = precision_score(labels, preds, zero_division=0)\n",
    "    rec = recall_score(labels, preds, zero_division=0)\n",
    "    f1  = f1_score(labels, preds, zero_division=0)\n",
    "\n",
    "    return {\"accuracy\": acc, \"precision\": pr, \"recall\": rec, \"f1\": f1}\n",
    "\n",
    "# class weights (si existen)\n",
    "cw = None\n",
    "meta_path = BASE_ARTI / \"preprocess_meta.json\"\n",
    "if meta_path.exists():\n",
    "    meta = json.loads(meta_path.read_text())\n",
    "    if \"class_weights\" in meta and isinstance(meta[\"class_weights\"], dict):\n",
    "        # admite claves \"0\"/\"1\" o 0/1\n",
    "        cw_map = {int(k): float(v) for k, v in meta[\"class_weights\"].items()}\n",
    "        cw = np.array([cw_map.get(0, 1.0), cw_map.get(1, 1.0)], dtype=np.float32)\n",
    "        print(\"Class weights:\", cw.tolist())\n",
    "\n",
    "config = AutoConfig.from_pretrained(\"distilroberta-base\", num_labels=2)\n",
    "model  = AutoModelForSequenceClassification.from_pretrained(\"distilroberta-base\", config=config)\n",
    "\n",
    "# Collator que ignora claves no usadas por el modelo y añade labels aparte\n",
    "class SafeCollator(DataCollatorWithPadding):\n",
    "    def __call__(self, features):\n",
    "        # recoge labels (acepta 'labels' o 'label')\n",
    "        labels = []\n",
    "        cleaned = []\n",
    "        for f in features:\n",
    "            if \"labels\" in f:\n",
    "                labels.append(f[\"labels\"])\n",
    "            elif \"label\" in f:\n",
    "                labels.append(f[\"label\"])\n",
    "            # solo claves esperadas por el modelo\n",
    "            nf = {}\n",
    "            for k in (\"input_ids\", \"attention_mask\", \"token_type_ids\"):\n",
    "                if k in f:\n",
    "                    nf[k] = f[k]\n",
    "            cleaned.append(nf)\n",
    "\n",
    "        batch = self.tokenizer.pad(cleaned, padding=True, return_tensors=\"pt\")\n",
    "        if labels:\n",
    "            batch[\"labels\"] = torch.tensor(labels, dtype=torch.long)\n",
    "        return batch\n",
    "\n",
    "collator = SafeCollator(tokenizer=tok, return_tensors=\"pt\")\n",
    "\n",
    "# Trainer con pérdida ponderada (si hay weights) y filtrado de inputs\n",
    "class WeightedTrainer(Trainer):\n",
    "    def __init__(self, class_weights=None, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.class_weights = (\n",
    "            torch.tensor(class_weights, dtype=torch.float32) if class_weights is not None else None\n",
    "        )\n",
    "\n",
    "    # En Transformers 4.56.x, Trainer pasa num_items_in_batch; lo aceptamos e ignoramos.\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        # Acepta 'labels' o 'label'\n",
    "        labels = inputs.pop(\"labels\", None)\n",
    "        if labels is None and \"label\" in inputs:\n",
    "            labels = inputs.pop(\"label\")\n",
    "        if labels is None:\n",
    "            raise ValueError(\"Missing 'labels' in inputs\")\n",
    "\n",
    "        # Filtra claves inesperadas (evita pasar id/context_id al modelo)\n",
    "        allowed = {\"input_ids\", \"attention_mask\", \"token_type_ids\"}\n",
    "        model_inputs = {k: v for k, v in inputs.items() if k in allowed}\n",
    "\n",
    "        outputs = model(**model_inputs)\n",
    "        logits = outputs.logits  # [B, 2]\n",
    "\n",
    "        # CrossEntropy con o sin pesos\n",
    "        if self.class_weights is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss(weight=self.class_weights.to(logits.device))\n",
    "        else:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "\n",
    "        loss = loss_fct(logits.view(-1, 2), labels.view(-1).long())\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "# --- TrainingArguments (compatible 4.x) ---\n",
    "from inspect import signature\n",
    "\n",
    "TA = TrainingArguments\n",
    "ta_params = set(signature(TA).parameters.keys())\n",
    "\n",
    "# Compat: algunas versiones usan 'eval_strategy' en vez de 'evaluation_strategy'\n",
    "eval_key = \"evaluation_strategy\" if \"evaluation_strategy\" in ta_params else (\n",
    "    \"eval_strategy\" if \"eval_strategy\" in ta_params else None\n",
    ")\n",
    "\n",
    "# 'report_to' en versiones recientes debe ser lista (no string)\n",
    "report_to_val = []  # equivalente a \"none\"\n",
    "\n",
    "ta_kwargs = dict(\n",
    "    output_dir=OUT_DIR,\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    gradient_accumulation_steps=2,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    fp16=torch.cuda.is_available(),  # ROCm AMP funciona vía torch.cuda en build ROCm\n",
    "    logging_steps=50,\n",
    "    report_to=report_to_val,\n",
    "    dataloader_num_workers=2,\n",
    "    remove_unused_columns=False,   # conservamos id/context_id en el dataset\n",
    "    save_total_limit=2,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "# Si existe clave de evaluación, la añadimos con \"epoch\"\n",
    "if eval_key is not None:\n",
    "    ta_kwargs[eval_key] = \"epoch\"\n",
    "else:\n",
    "    print(\"[warn] TrainingArguments sin evaluation_strategy/eval_strategy; usando configuración por defecto.\")\n",
    "\n",
    "args = TA(**ta_kwargs)\n",
    "\n",
    "trainer = WeightedTrainer(\n",
    "    class_weights=cw,\n",
    "    model=model, args=args,\n",
    "    train_dataset=ds[\"train\"],\n",
    "    eval_dataset=ds[\"validation\"],\n",
    "    tokenizer=tok,\n",
    "    data_collator=collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "SAVE_DIR = \"/checkpoints/model_distilroberta_ft\"\n",
    "trainer.save_model(SAVE_DIR)\n",
    "tok.save_pretrained(SAVE_DIR)\n",
    "print(\"Modelo guardado en:\", SAVE_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0009f8063323c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "## Calibración de umbral (en validación, con pooling por comentario)\n",
    "### Obtenemos logits por ventana y agrupamos por comentario (id + context_id).\n",
    "### Elegimos el umbral que maximiza recall con precisión ≥ objetivo (ajústalo).\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import defaultdict\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "try:\n",
    "    from scipy.special import softmax\n",
    "except Exception:\n",
    "    def softmax(x, axis=-1):\n",
    "        x = np.asarray(x)\n",
    "        x = x - np.max(x, axis=axis, keepdims=True)\n",
    "        expx = np.exp(x)\n",
    "        return expx / np.sum(expx, axis=axis, keepdims=True)\n",
    "\n",
    "TARGET_PREC = 0.90  # ajusta tu objetivo\n",
    "\n",
    "collator_eval = DataCollatorWithPadding(tokenizer=tok, return_tensors=\"pt\")\n",
    "\n",
    "# DataLoader conservando metadatos y aplicando padding dinámico\n",
    "def make_loader(split, bs=64):\n",
    "    d = ds[split]\n",
    "\n",
    "    def collate(ex):\n",
    "        # features para el modelo (pad con collator)\n",
    "        feats = []\n",
    "        for e in ex:\n",
    "            item = {\n",
    "                \"input_ids\": e[\"input_ids\"],\n",
    "                \"attention_mask\": e[\"attention_mask\"],\n",
    "            }\n",
    "            # estandariza a 'labels' si está disponible\n",
    "            if \"labels\" in e:\n",
    "                item[\"labels\"] = e[\"labels\"]\n",
    "            elif \"label\" in e:\n",
    "                item[\"labels\"] = e[\"label\"]\n",
    "            feats.append(item)\n",
    "        batch = collator_eval(feats)\n",
    "        meta = {\"id\": [e.get(\"id\") for e in ex], \"context_id\": [e.get(\"context_id\") for e in ex]}\n",
    "        return batch, meta\n",
    "\n",
    "    return DataLoader(d, batch_size=bs, shuffle=False, collate_fn=collate)\n",
    "\n",
    "# logits + metadatos\n",
    "def logits_with_meta(split):\n",
    "    loader = make_loader(split)\n",
    "    mdl = trainer.model.to(DEVICE).eval()\n",
    "    all_logits, all_labels, all_ids, all_ctx = [], [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (batch, meta) in loader:\n",
    "            labels = batch.pop(\"labels\", None)\n",
    "            for k in (\"input_ids\", \"attention_mask\", \"token_type_ids\"):\n",
    "                if k in batch:\n",
    "                    batch[k] = batch[k].to(DEVICE)\n",
    "            out = mdl(**batch).logits.detach().cpu().numpy()\n",
    "            all_logits.append(out)\n",
    "            if labels is not None:\n",
    "                all_labels.append(labels.numpy())\n",
    "            all_ids.extend(meta[\"id\"])\n",
    "            all_ctx.extend(meta[\"context_id\"])\n",
    "\n",
    "    labels_arr = np.concatenate(all_labels) if all_labels else None\n",
    "    return np.vstack(all_logits), labels_arr, np.array(all_ids), np.array(all_ctx)\n",
    "\n",
    "# pooling por comentario (máx logit)\n",
    "def pool_comment_metrics(split, threshold):\n",
    "    logits, labels, ids, ctx = logits_with_meta(split)\n",
    "    bucket = defaultdict(lambda: {\"logits\":[], \"label\":None})\n",
    "\n",
    "    # Si no hay labels (no debería ocurrir en val/test), aborta con métricas vacías\n",
    "    if labels is None:\n",
    "        return dict(precision=0.0, recall=0.0, f1=0.0, accuracy=0.0, counts=dict(tp=0,fp=0,fn=0,tn=0))\n",
    "\n",
    "    for i in range(len(ids)):\n",
    "        key = (ids[i], ctx[i])   # o solo id, si prefieres\n",
    "        bucket[key][\"logits\"].append(logits[i])\n",
    "        bucket[key][\"label\"] = int(labels[i])\n",
    "\n",
    "    tp=fp=fn=tn=0\n",
    "\n",
    "    for _, v in bucket.items():\n",
    "        L = np.stack(v[\"logits\"], axis=0)   # [num_windows, 2]\n",
    "        pooled = L.max(axis=0)              # máx por clase\n",
    "        p1 = softmax(pooled)[1]\n",
    "        pred = int(p1 >= threshold)\n",
    "        y    = v[\"label\"]\n",
    "        tp += int(pred==1 and y==1); fp += int(pred==1 and y==0)\n",
    "        fn += int(pred==0 and y==1); tn += int(pred==0 and y==0)\n",
    "\n",
    "    prec = tp/(tp+fp+1e-9); rec = tp/(tp+fn+1e-9)\n",
    "    f1   = 2*prec*rec/(prec+rec+1e-9); acc = (tp+tn)/(tp+tn+fp+fn+1e-9)\n",
    "\n",
    "    return dict(precision=prec, recall=rec, f1=f1, accuracy=acc, counts=dict(tp=tp,fp=fp,fn=fn,tn=tn))\n",
    "\n",
    "# Barrido de umbral en VALIDATION\n",
    "best_t, best_rec = 0.5, -1.0\n",
    "\n",
    "for t in np.linspace(0.05, 0.95, 181):\n",
    "    m = pool_comment_metrics(\"validation\", t)\n",
    "    if m[\"precision\"] >= TARGET_PREC and m[\"recall\"] > best_rec:\n",
    "        best_t, best_rec = t, m[\"recall\"]\n",
    "\n",
    "# guarda threshold\n",
    "from pathlib import Path as _Path\n",
    "thr_path = _Path(SAVE_DIR) / \"threshold.json\"\n",
    "thr_path.write_text(json.dumps({\"threshold\": float(best_t),\n",
    "                                \"target_precision\": TARGET_PREC,\n",
    "                                \"recall_at_threshold\": float(best_rec)}, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "print(\"threshold:\", best_t, \"recall@\", TARGET_PREC, \"=\", best_rec)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abed048bb36f0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calibración autónoma desde disco (sin reentrenar)\n",
    "from pathlib import Path\n",
    "import json, numpy as np, torch\n",
    "from datasets import load_from_disk\n",
    "from transformers import (AutoTokenizer, AutoConfig, AutoModelForSequenceClassification,\n",
    "                          TrainingArguments, Trainer, DataCollatorWithPadding)\n",
    "\n",
    "# RUTAS — AJUSTA si las cambiaste\n",
    "BASE_ARTI = Path(\"/content/artifacts/hf_distilroberta\")   # contiene dataset/, tokenizer/\n",
    "SAVE_DIR  = \"/content/drive/MyDrive/BERTolto/model_distilroberta_ft\"  # modelo final guardado\n",
    "OUT_TMP   = \"/content/tmp_calib\"\n",
    "\n",
    "# 1) Dataset y tokenizer\n",
    "ds  = load_from_disk(str(BASE_ARTI / \"dataset\"))\n",
    "tok = AutoTokenizer.from_pretrained(str(BASE_ARTI / \"tokenizer\"), use_fast=True)\n",
    "\n",
    "# 2) Modelo (final). Si no existiera SAVE_DIR, podrías usar un checkpoint de OUT_DIR/checkpoint-XXXX/\n",
    "config = AutoConfig.from_pretrained(SAVE_DIR)\n",
    "model  = AutoModelForSequenceClassification.from_pretrained(SAVE_DIR, config=config)\n",
    "\n",
    "# 3) Trainer “ligero” solo para predict\n",
    "args = TrainingArguments(output_dir=OUT_TMP,\n",
    "                         per_device_eval_batch_size=128,\n",
    "                         fp16=torch.cuda.is_available(),\n",
    "                         dataloader_num_workers=2,\n",
    "                         report_to=[])\n",
    "trainer = Trainer(model=model, args=args, processing_class=tok,\n",
    "                  data_collator=DataCollatorWithPadding(tokenizer=tok, return_tensors=\"pt\"))\n",
    "\n",
    "# --- Calibración rápida (un único predict) ---\n",
    "def _prepare_pred_dataset(split):\n",
    "    d = ds[split]\n",
    "    cols = d.column_names\n",
    "    label_col = \"labels\" if \"labels\" in cols else (\"label\" if \"label\" in cols else None)\n",
    "    assert label_col is not None, f\"Split {split} sin columna de label.\"\n",
    "    keep = [\"input_ids\", \"attention_mask\", label_col] + ([\"token_type_ids\"] if \"token_type_ids\" in cols else [])\n",
    "    ids = d[\"id\"] if \"id\" in cols else list(range(len(d)))\n",
    "    ctx = d[\"context_id\"] if \"context_id\" in cols else [0] * len(d)\n",
    "    pred_ds = d.remove_columns([c for c in cols if c not in keep])\n",
    "    labels = np.array(d[label_col])\n",
    "    return pred_ds, labels, np.array(ids), np.array(ctx)\n",
    "\n",
    "def logits_labels_ids(split):\n",
    "    pred_ds, labels, ids, ctx = _prepare_pred_dataset(split)\n",
    "    pred_out = trainer.predict(pred_ds)\n",
    "    logits = pred_out.predictions  # [N, 2]\n",
    "    return logits, labels, ids, ctx\n",
    "\n",
    "def softmax_np(x):\n",
    "    x = x - x.max(axis=-1, keepdims=True)\n",
    "    ex = np.exp(x)\n",
    "    return ex / ex.sum(axis=-1, keepdims=True)\n",
    "\n",
    "logits_val, labels_val, ids_val, ctx_val = logits_labels_ids(\"validation\")\n",
    "p1_val = softmax_np(logits_val)[:, 1]\n",
    "\n",
    "keys = np.core.defchararray.add(ids_val.astype(str), \"::\" + ctx_val.astype(str))\n",
    "order = np.argsort(keys)\n",
    "keys_s, p1_s, y_s = keys[order], p1_val[order], labels_val[order]\n",
    "grp_st = np.r_[0, 1 + np.flatnonzero(keys_s[1:] != keys_s[:-1])]\n",
    "pooled_p1 = np.maximum.reduceat(p1_s, grp_st)\n",
    "pooled_y  = y_s[grp_st].astype(int)\n",
    "\n",
    "TARGET_PREC = 0.90\n",
    "ord_desc = np.argsort(-pooled_p1)\n",
    "scores = pooled_p1[ord_desc]\n",
    "y_true = pooled_y[ord_desc]\n",
    "tp = np.cumsum(y_true); fp = np.cumsum(1 - y_true); fn_tot = y_true.sum()\n",
    "prec = tp / np.maximum(tp + fp, 1e-9)\n",
    "rec  = tp / np.maximum(fn_tot, 1e-9)\n",
    "mask = prec >= TARGET_PREC\n",
    "best_idx = int(np.argmax(rec * mask)) if np.any(mask) else int(np.argmax(prec))\n",
    "best_thr, best_prec, best_rec = float(scores[best_idx]), float(prec[best_idx]), float(rec[best_idx])\n",
    "\n",
    "Path(SAVE_DIR, \"threshold.json\").write_text(json.dumps({\n",
    "    \"threshold\": best_thr,\n",
    "    \"target_precision\": TARGET_PREC,\n",
    "    \"precision_at_threshold\": best_prec,\n",
    "    \"recall_at_threshold\": best_rec\n",
    "}, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "print(f\"[calibración] threshold={best_thr:.4f} | precision={best_prec:.4f} | recall={best_rec:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5d75fcc0064644",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "## Calibración de umbral (REEMPLAZADO — usa trainer.predict)\n",
    "### Obtenemos logits por ventana y agrupamos por comentario (id + context_id).\n",
    "### Elegimos el umbral que maximiza recall con precisión ≥ objetivo (ajústalo).\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "try:\n",
    "    from scipy.special import softmax\n",
    "except Exception:\n",
    "    def softmax(x, axis=-1):\n",
    "        x = np.asarray(x)\n",
    "        x = x - np.max(x, axis=axis, keepdims=True)\n",
    "        expx = np.exp(x)\n",
    "        return expx / np.sum(expx, axis=axis, keepdims=True)\n",
    "\n",
    "TARGET_PREC = 0.90  # ajusta tu objetivo\n",
    "\n",
    "def _prepare_pred_dataset(split):\n",
    "\n",
    "    #Devuelve (pred_ds, labels, ids, ctx) para usar con trainer.predict,\n",
    "    #eliminando columnas no usadas por el modelo para evitar errores.\n",
    "\n",
    "    d = ds[split]\n",
    "    cols = d.column_names\n",
    "\n",
    "    # Identifica columna de label\n",
    "    if \"labels\" in cols:\n",
    "        label_col = \"labels\"\n",
    "    elif \"label\" in cols:\n",
    "        label_col = \"label\"\n",
    "    else:\n",
    "        raise AssertionError(f\"No se encontró columna de label en split='{split}'.\")\n",
    "\n",
    "    # Columnas necesarias para el modelo\n",
    "    keep = [\"input_ids\", \"attention_mask\", label_col]\n",
    "    if \"token_type_ids\" in cols:\n",
    "        keep.append(\"token_type_ids\")\n",
    "\n",
    "    # Extrae metadatos antes de eliminar columnas\n",
    "    ids = d[\"id\"] if \"id\" in cols else list(range(len(d)))\n",
    "    ctx = d[\"context_id\"] if \"context_id\" in cols else [0] * len(d)\n",
    "    labels = np.array(d[label_col])\n",
    "\n",
    "    # Dataset solo con columnas esperadas por el modelo\n",
    "    pred_ds = d.remove_columns([c for c in cols if c not in keep])\n",
    "    return pred_ds, labels, np.array(ids), np.array(ctx)\n",
    "\n",
    "def logits_with_meta(split):\n",
    "\n",
    "    #Usa trainer.predict sobre un dataset reducido (sin columnas extra)\n",
    "    #y devuelve (logits, labels, ids, ctx).\n",
    "\n",
    "    pred_ds, labels, ids, ctx = _prepare_pred_dataset(split)\n",
    "    pred_out = trainer.predict(pred_ds)\n",
    "    logits = pred_out.predictions  # shape [N, 2]\n",
    "    return logits, labels, ids, ctx\n",
    "\n",
    "# pooling por comentario (máx logit)\n",
    "def pool_comment_metrics(split, threshold):\n",
    "    logits, labels, ids, ctx = logits_with_meta(split)\n",
    "    bucket = defaultdict(lambda: {\"logits\": [], \"label\": None})\n",
    "\n",
    "    for i in range(len(ids)):\n",
    "        key = (ids[i], ctx[i])   # o solo id, si prefieres\n",
    "        bucket[key][\"logits\"].append(logits[i])\n",
    "        bucket[key][\"label\"] = int(labels[i])\n",
    "\n",
    "    tp = fp = fn = tn = 0\n",
    "\n",
    "    for _, v in bucket.items():\n",
    "        L = np.stack(v[\"logits\"], axis=0)   # [num_windows, 2]\n",
    "        pooled = L.max(axis=0)              # máx por clase\n",
    "        p1 = softmax(pooled)[1]\n",
    "        pred = int(p1 >= threshold)\n",
    "        y = v[\"label\"]\n",
    "        tp += int(pred == 1 and y == 1); fp += int(pred == 1 and y == 0)\n",
    "        fn += int(pred == 0 and y == 1); tn += int(pred == 0 and y == 0)\n",
    "\n",
    "    prec = tp / (tp + fp + 1e-9); rec = tp / (tp + fn + 1e-9)\n",
    "    f1   = 2 * prec * rec / (prec + rec + 1e-9)\n",
    "    acc  = (tp + tn) / (tp + tn + fp + fn + 1e-9)\n",
    "\n",
    "    return dict(precision=prec, recall=rec, f1=f1, accuracy=acc,\n",
    "                counts=dict(tp=tp, fp=fp, fn=fn, tn=tn))\n",
    "\n",
    "# Barrido de umbral en VALIDATION\n",
    "best_t, best_rec = 0.5, -1.0\n",
    "for t in np.linspace(0.05, 0.95, 181):\n",
    "    m = pool_comment_metrics(\"validation\", t)\n",
    "    if m[\"precision\"] >= TARGET_PREC and m[\"recall\"] > best_rec:\n",
    "        best_t, best_rec = t, m[\"recall\"]\n",
    "\n",
    "# Guardado del threshold\n",
    "from pathlib import Path as _Path\n",
    "thr_path = _Path(SAVE_DIR) / \"threshold.json\"\n",
    "thr_path.write_text(json.dumps({\n",
    "    \"threshold\": float(best_t),\n",
    "    \"target_precision\": TARGET_PREC,\n",
    "    \"recall_at_threshold\": float(best_rec)\n",
    "}, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "print(\"threshold:\", best_t, \"recall@\", TARGET_PREC, \"=\", best_rec)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f4f63d36449468",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluación final en TEST (pooling por comentario)\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "thr = json.loads((Path(SAVE_DIR) / \"threshold.json\").read_text())[\"threshold\"]\n",
    "val_metrics  = pool_comment_metrics(\"validation\", thr)\n",
    "test_metrics = pool_comment_metrics(\"test\", thr)\n",
    "\n",
    "(Path(SAVE_DIR) / \"eval_comment_level.json\").write_text(\n",
    "    json.dumps({\"validation\": val_metrics, \"test\": test_metrics}, indent=2),\n",
    "    encoding=\"utf-8\"\n",
    ")\n",
    "\n",
    "(Path(SAVE_DIR) / \"inference_meta.json\").write_text(\n",
    "    json.dumps({\"pooling\":\"max\", \"threshold\": float(thr)}, indent=2),\n",
    "    encoding=\"utf-8\"\n",
    ")\n",
    "\n",
    "print(\"VAL:\", val_metrics)\n",
    "print(\"TEST:\", test_metrics)\n",
    "print(\"Guardado en:\", SAVE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef0f33d0ca143b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## \"Pack\" final listo para reutilizar/re-entrenar\n",
    "DEPLOY_DIR = \"/content/drive/MyDrive/BERTolto/deploy_distilroberta\"\n",
    "!rm -rf \"$DEPLOY_DIR\"\n",
    "!mkdir -p \"$DEPLOY_DIR\"\n",
    "!cp -r \"$SAVE_DIR\"/* \"$DEPLOY_DIR\"/\n",
    "print(\"Pack listo en:\", DEPLOY_DIR)\n",
    "!ls -la \"$DEPLOY_DIR\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
